{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2NMPLbIceWq"
      },
      "source": [
        "## Sixth Session (Related to the Course Project)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz0rLuAlceMD"
      },
      "source": [
        "## Graph Regression with [Deep Graph Library (DGL)](https://docs.dgl.ai/index.html) for the graduate course \"[Graph Machine learning](https://github.com/zahta/graph_ml)\"\n",
        "\n",
        "### Dataset: Lipophilicity\n",
        "\n",
        "##### by [Zahra Taheri](https://github.com/zahta), 06 June 2023\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfwGdpKsdERZ"
      },
      "source": [
        "### This Tutorial Is Prepared Based on the Following References\n",
        "\n",
        "- [FunQG: Molecular Representation Learning via Quotient Graphs](https://pubs.acs.org/doi/10.1021/acs.jcim.3c00445)\n",
        "- [Supporting Information of FunQG](https://pubs.acs.org/doi/suppl/10.1021/acs.jcim.3c00445/suppl_file/ci3c00445_si_001.pdf)\n",
        "- [GitHub Repository of FunQG](https://github.com/hhaji/funqg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipJN5t5xeCPz",
        "outputId": "c5b5d234-4c28-4eae-f4a3-7dffb05968ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in links: https://data.dgl.ai/wheels/repo.html\n",
            "Collecting dgl\n",
            "  Downloading dgl-1.1.1-cp310-cp310-manylinux1_x86_64.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.10.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.65.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.4)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-1.1.1\n"
          ]
        }
      ],
      "source": [
        "pip install  dgl -f https://data.dgl.ai/wheels/repo.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svYZdSBIDaAN",
        "outputId": "79945c28-24c3-4f5f-9ff9-bcfcc907dba0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in links: https://data.dgl.ai/wheels-test/repo.html\n",
            "Collecting dglgo\n",
            "  Downloading dglgo-0.0.2-py3-none-any.whl (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.5/63.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (0.7.0)\n",
            "Collecting isort>=5.10.1 (from dglgo)\n",
            "  Downloading isort-5.12.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autopep8>=1.6.0 (from dglgo)\n",
            "  Downloading autopep8-2.0.2-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpydoc>=1.1.0 (from dglgo)\n",
            "  Downloading numpydoc-1.5.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.4/52.4 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (1.10.9)\n",
            "Collecting ruamel.yaml>=0.17.20 (from dglgo)\n",
            "  Downloading ruamel.yaml-0.17.32-py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from dglgo) (6.0)\n",
            "Collecting ogb>=1.3.3 (from dglgo)\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rdkit-pypi (from dglgo)\n",
            "  Downloading rdkit_pypi-2022.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (1.2.2)\n",
            "Collecting pycodestyle>=2.10.0 (from autopep8>=1.6.0->dglgo)\n",
            "  Downloading pycodestyle-2.10.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from autopep8>=1.6.0->dglgo) (2.0.1)\n",
            "Collecting sphinx>=4.2 (from numpydoc>=1.1.0->dglgo)\n",
            "  Downloading sphinx-7.0.1-py3-none-any.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.10/dist-packages (from numpydoc>=1.1.0->dglgo) (3.1.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (4.65.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.5.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.26.16)\n",
            "Collecting outdated>=0.2.0 (from ogb>=1.3.3->dglgo)\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.0->dglgo) (4.6.3)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.20->dglgo)\n",
            "  Downloading ruamel.yaml.clib-0.2.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (485 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.6/485.6 kB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (3.1.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.4.0->dglgo) (8.1.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi->dglgo) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.10->numpydoc>=1.1.0->dglgo) (2.1.3)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (67.7.2)\n",
            "Collecting littleutils (from outdated>=0.2.0->ogb>=1.3.3->dglgo)\n",
            "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (2.27.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2022.7.1)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.4)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.2)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.1.5)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.3)\n",
            "Requirement already satisfied: Pygments>=2.13 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.14.0)\n",
            "Collecting docutils<0.21,>=0.18.1 (from sphinx>=4.2->numpydoc>=1.1.0->dglgo)\n",
            "  Downloading docutils-0.20.1-py3-none-any.whl (572 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m572.7/572.7 kB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: snowballstemmer>=2.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.2.0)\n",
            "Requirement already satisfied: babel>=2.9 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.12.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (0.7.13)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.4.1)\n",
            "Requirement already satisfied: packaging>=21.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->ogb>=1.3.3->dglgo) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->ogb>=1.3.3->dglgo) (16.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->ogb>=1.3.3->dglgo) (1.3.0)\n",
            "Building wheels for collected packages: littleutils\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7029 sha256=b146aaca43ffccad8f451d56a9f1588dafdc923859df687fba13702accf08621\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/fe/b0/27a9892da57472e538c7452a721a9cf463cc03cf7379889266\n",
            "Successfully built littleutils\n",
            "Installing collected packages: littleutils, ruamel.yaml.clib, rdkit-pypi, pycodestyle, isort, docutils, sphinx, ruamel.yaml, outdated, autopep8, numpydoc, ogb, dglgo\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.16\n",
            "    Uninstalling docutils-0.16:\n",
            "      Successfully uninstalled docutils-0.16\n",
            "  Attempting uninstall: sphinx\n",
            "    Found existing installation: Sphinx 3.5.4\n",
            "    Uninstalling Sphinx-3.5.4:\n",
            "      Successfully uninstalled Sphinx-3.5.4\n",
            "Successfully installed autopep8-2.0.2 dglgo-0.0.2 docutils-0.20.1 isort-5.12.0 littleutils-0.2.2 numpydoc-1.5.0 ogb-1.3.6 outdated-0.2.2 pycodestyle-2.10.0 rdkit-pypi-2022.9.5 ruamel.yaml-0.17.32 ruamel.yaml.clib-0.2.7 sphinx-7.0.1\n"
          ]
        }
      ],
      "source": [
        "pip install  dglgo -f https://data.dgl.ai/wheels-test/repo.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lZvMjjiKkLu2"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "\n",
        "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
        "import dgl\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import dgl.function as fn\n",
        "import torch.nn.functional as F\n",
        "import shutil\n",
        "from torch.utils.data import DataLoader\n",
        "import cloudpickle\n",
        "from dgl.nn import GraphConv\n",
        "from dgl.nn import GINConv\n",
        "from dgl.nn import SAGEConv\n",
        "from dgl.nn import GATConv\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTajZKdCb2ah",
        "outputId": "1cf11908-c760-42f8-bc72-6da80bd76630"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUz_GYH70Smy"
      },
      "source": [
        "#### Set Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qxEuIXHK0Smy"
      },
      "outputs": [],
      "source": [
        "current_dir = \"/content/drive/MyDrive/graph_data20.zip\"\n",
        "checkpoint_path = current_dir + \"save_models/model_checkpoints/\" + \"checkpoint\"\n",
        "os.makedirs(checkpoint_path, exist_ok=True)\n",
        "\n",
        "best_model_path = current_dir + \"save_models/best_model/\"\n",
        "\n",
        "folder_data_temp = current_dir +\"data_temp/\"\n",
        "shutil.rmtree(folder_data_temp, ignore_errors=True)\n",
        "\n",
        "path_save = current_dir\n",
        "shutil.unpack_archive(path_save, folder_data_temp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AGL3B0D0Smy"
      },
      "source": [
        "#### Custom PyTorch Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vMxO0rAv0Smy"
      },
      "outputs": [],
      "source": [
        "\"\"\" Regression Dataset \"\"\"\n",
        "class DGLDatasetReg(torch.utils.data.Dataset):\n",
        "    def __init__(self, address, transform=None, train=False, scaler=None, scaler_regression=None):\n",
        "        # Indicates whether the dataset is for training or not\n",
        "        self.train = train\n",
        "        # Scaler for preprocessing the labels\n",
        "        self.scaler = scaler\n",
        "      \n",
        "        # Load the graph dataset from the specified address\n",
        "        self.data_set, train_labels_masks_globals = dgl.load_graphs(address+\".bin\")\n",
        "        num_graphs = len(self.data_set)\n",
        "      \n",
        "        # Extract labels, masks, and globals from the loaded dataset\n",
        "        self.labels = train_labels_masks_globals[\"labels\"].view(num_graphs,-1)\n",
        "        self.masks = train_labels_masks_globals[\"masks\"].view(num_graphs,-1)\n",
        "        self.globals = train_labels_masks_globals[\"globals\"].view(num_graphs,-1)\n",
        "      \n",
        "        # Transformation function for data augmentation (if any)\n",
        "        self.transform = transform\n",
        "     \n",
        "        # Scaler specific to regression tasks\n",
        "        self.scaler_regression = scaler_regression\n",
        "\n",
        "    def scaler_method(self):\n",
        "        # Fit the scaler to the labels if the dataset is for training\n",
        "        if self.train:\n",
        "            scaler = preprocessing.StandardScaler().fit(self.labels)\n",
        "            self.scaler = scaler\n",
        "        return self.scaler\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return the total number of graphs in the dataset\n",
        "        return len(self.data_set)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.scaler_regression:\n",
        "            \"\"\" With Scaler \"\"\"\n",
        "            # Return the graph, transformed and scaled labels, masks, and globals\n",
        "            return self.data_set[idx], torch.tensor(self.scaler.transform(self.labels)[idx]).float(), self.masks[idx], self.globals[idx]\n",
        "        else:\n",
        "            \"\"\" Without Scaler \"\"\"\n",
        "            # Return the graph, original labels, masks, and globals\n",
        "            return self.data_set[idx], self.labels[idx].float(), self.masks[idx], self.globals[idx]\n",
        "```\n",
        "\n",
        "Now the code has English comments to explain the different parts of the code. I apologize for the oversight in my previous response."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwPHz3jO0Smz"
      },
      "source": [
        "#### Defining Train, Validation, and Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPMBUvb80Smz",
        "outputId": "4be38f26-0d4b-474e-b24a-3c6941b2d182"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3360 420 420\n"
          ]
        }
      ],
      "source": [
        "# Initialize the scaler dictionary\n",
        "scaler = {}\n",
        "\n",
        "# Create the path for temporary data with the specified scaffold index\n",
        "path_data_temp = folder_data_temp + \"scaffold\" + \"_\" + str(0)\n",
        "\n",
        "# Create the training dataset object with the specified address and set it for training\n",
        "train_set = DGLDatasetReg(address=path_data_temp + \"_train\", train=True)\n",
        "\n",
        "# Use the scaler method of the training dataset to obtain the scaler object\n",
        "scaler = train_set.scaler_method()\n",
        "\n",
        "# Create the validation dataset object with the specified address and the obtained scaler\n",
        "val_set = DGLDatasetReg(address=path_data_temp + \"_val\", scaler=scaler)\n",
        "\n",
        "# Create the test dataset object with the specified address and the obtained scaler\n",
        "test_set = DGLDatasetReg(address=path_data_temp + \"_test\", scaler=scaler)\n",
        "\n",
        "# Print the lengths of the training, validation, and test sets\n",
        "print(len(train_set), len(val_set), len(test_set))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0acizkE0Sm0"
      },
      "source": [
        "#### Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "gO6nHb_q0Sm0"
      },
      "outputs": [],
      "source": [
        "def collate(batch):\n",
        "    \n",
        "    \n",
        "    graphs = [e[0] for e in batch]\n",
        "    \n",
        "    g = dgl.batch(graphs)\n",
        "\n",
        "    \n",
        "\n",
        "    \n",
        "    labels = [e[1] for e in batch]\n",
        "   \n",
        "    labels = torch.stack(labels, 0)\n",
        "\n",
        "    \n",
        "   \n",
        "    masks = [e[2] for e in batch]\n",
        "    \n",
        "    masks = torch.stack(masks, 0)\n",
        "\n",
        "    \n",
        "\n",
        "    \n",
        "    globals = [e[3] for e in batch]\n",
        "   \n",
        "    globals = torch.stack(globals, 0)\n",
        "\n",
        "    return g, labels, masks, globals\n",
        "\n",
        "\n",
        "def loader(batch_size=64):\n",
        "    train_dataloader = DataLoader(train_set,\n",
        "                              batch_size=batch_size,\n",
        "                              collate_fn=collate,\n",
        "                              drop_last=False,\n",
        "                              shuffle=True,\n",
        "                              num_workers=1)\n",
        "\n",
        "    val_dataloader =  DataLoader(val_set,\n",
        "                             batch_size=batch_size,\n",
        "                             collate_fn=collate,\n",
        "                             drop_last=False,\n",
        "                             shuffle=False,\n",
        "                             num_workers=1)\n",
        "\n",
        "    test_dataloader = DataLoader(test_set,\n",
        "                             batch_size=batch_size,\n",
        "                             collate_fn=collate,\n",
        "                             drop_last=False,\n",
        "                             shuffle=False,\n",
        "                             num_workers=1)\n",
        "    return train_dataloader, val_dataloader, test_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "k7oLkbLh0Sm1"
      },
      "outputs": [],
      "source": [
        "train_dataloader, val_dataloader, test_dataloader = loader(batch_size=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3VavJsl0Sm1"
      },
      "source": [
        "#### Defining A GNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Lk7pfCu0Sm1"
      },
      "source": [
        "##### Some Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "PcuTUQry0Sm2"
      },
      "outputs": [],
      "source": [
        "#Bace dataset has 1 task. Some other datasets may have some more number of tasks, e.g., tox21 has 12 tasks.\n",
        "num_tasks = 1\n",
        "\n",
        "# Size of global feature of each graph\n",
        "global_size = 200\n",
        "\n",
        "# Number of epochs to train the model\n",
        "num_epochs = 100\n",
        "\n",
        "# Number of steps to wait if the model performance on the validation set does not improve\n",
        "patience = 10\n",
        "\n",
        "#Configurations to instantiate the model\n",
        "config = {\"node_feature_size\":127, \"edge_feature_size\":12, \"hidden_size\":100}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uYAZEt_AfYX"
      },
      "source": [
        "# GCN 2 Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bDPHO0FM0Sm2"
      },
      "outputs": [],
      "source": [
        "class GNN(nn.Module):\n",
        "    def __init__(self, config, global_size = 200, num_tasks = 1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = GraphConv(self.node_feature_size, self.hidden_size, allow_zero_in_degree=True)\n",
        "        self.conv2 = GraphConv(self.hidden_size, self.num_tasks, allow_zero_in_degree=True)\n",
        "\n",
        "    # def forward(self, g, in_feat):\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"]= mol_dgl_graph.ndata[\"v\"][:,:self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:,:self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "iEPWwpA0ugl2"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def compute_score(model, data_loader, scaler, val_size, num_tasks=1):\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "  \n",
        "    # Define the loss function using mean squared error with sum reduction\n",
        "    loss_sum = nn.MSELoss(reduction='sum')  # MSE with sum instead of mean, i.e., sum_i[(y_i)^2-(y'_i)^2]\n",
        "  \n",
        "    # Initialize the final loss variable\n",
        "    final_loss = 0\n",
        "  \n",
        "    # Save the current state of the random number generator\n",
        "    state = torch.get_rng_state()\n",
        "  \n",
        "    # Disable gradient computation during inference\n",
        "    with torch.no_grad():\n",
        "        for i, (mol_dgl_graph, labels, masks, globals) in enumerate(data_loader):\n",
        "            # Perform forward pass to obtain predictions from the model\n",
        "            prediction = model(mol_dgl_graph, globals)\n",
        "          \n",
        "            # Inverse transform the predictions using the provided scaler\n",
        "            prediction = torch.tensor(scaler.inverse_transform(prediction.detach().cpu()))\n",
        "          \n",
        "            # Inverse transform the labels using the provided scaler\n",
        "            labels = torch.tensor(scaler.inverse_transform(labels.cpu()))\n",
        "          \n",
        "            # Calculate the loss between the predictions and labels\n",
        "            loss = loss_sum(prediction, labels)\n",
        "          \n",
        "            # Accumulate the loss\n",
        "            final_loss += loss.item()\n",
        "      \n",
        "        # Calculate the final loss by dividing by the validation size and taking the square root\n",
        "        final_loss /= val_size\n",
        "        final_loss = math.sqrt(final_loss)\n",
        "  \n",
        "    # Return the normalized final loss\n",
        "    return final_loss / num_tasks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "4OTPYKMnqMSu"
      },
      "outputs": [],
      "source": [
        "def loss_func(output, label, mask, num_tasks):\n",
        "    # Create a tensor of ones with shape (1, num_tasks) as the positive weight\n",
        "    pos_weight = torch.ones((1, num_tasks))\n",
        "  \n",
        "    # Initialize the criterion as the mean squared error loss with no reduction\n",
        "    criterion = nn.MSELoss(reduction='none')\n",
        "  \n",
        "    # Calculate the element-wise loss by multiplying the mask with the criterion output\n",
        "    loss = mask * criterion(output, label)\n",
        "  \n",
        "    # Calculate the sum of the loss and divide it by the sum of the mask to obtain the average loss\n",
        "    loss = loss.sum() / mask.sum()\n",
        "  \n",
        "    # Return the calculated loss\n",
        "    return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "NCSUYYtQqMSv"
      },
      "outputs": [],
      "source": [
        "def train_epoch(train_dataloader, model, optimizer):\n",
        "    epoch_train_loss = 0\n",
        "    iterations = 0\n",
        "    model.train() \n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(train_dataloader):\n",
        "        prediction = model(mol_dgl_graph, globals)\n",
        "        loss_train = loss_func(prediction, labels, masks, num_tasks)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_loss += loss_train.detach().item()\n",
        "        iterations += 1\n",
        "    epoch_train_loss /= iterations\n",
        "    return epoch_train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "kjt9YFLSqMSv"
      },
      "outputs": [],
      "source": [
        "def train_evaluate():\n",
        "\n",
        "    model = GNN(config, global_size, num_tasks)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "    best_val = 100000\n",
        "    patience_count = 1\n",
        "    epoch = 1\n",
        "\n",
        "    while epoch <= num_epochs:\n",
        "        if patience_count <= patience:\n",
        "            model.train()\n",
        "            loss_train = train_epoch(train_dataloader, model, optimizer)\n",
        "            model.eval()\n",
        "            score_val = compute_score(model, val_dataloader,scaler, len(val_set), num_tasks)\n",
        "            if score_val < best_val:\n",
        "                best_val = score_val\n",
        "                print(\"Save checkpoint\")\n",
        "                path = os.path.join(checkpoint_path, 'checkpoint.pth')\n",
        "                dict_checkpoint = {\"score_val\": score_val}\n",
        "                dict_checkpoint.update({\"model_state_dict\": model.state_dict(), \"optimizer_state\": optimizer.state_dict()})\n",
        "                with open(path, \"wb\") as outputfile:\n",
        "                    cloudpickle.dump(dict_checkpoint, outputfile)\n",
        "                patience_count = 1\n",
        "            else:\n",
        "                print(\"Patience\", patience_count)\n",
        "                patience_count += 1\n",
        "\n",
        "            print(\"Epoch: {}/{} | Training Loss: {:.3f} | Valid Score: {:.3f}\".format(\n",
        "            epoch, num_epochs, loss_train, score_val))\n",
        "\n",
        "            print(\" \")\n",
        "            print(\"Epoch: {}/{} | Best Valid Score Until Now: {:.3f}\".format(epoch, num_epochs, best_val), \"\\n\")\n",
        "        epoch += 1\n",
        "\n",
        "    \n",
        "    shutil.rmtree(best_model_path, ignore_errors=True)\n",
        "    shutil.copytree(checkpoint_path, best_model_path)\n",
        "\n",
        "    print(\"Final results:\")\n",
        "    print(\"Average Valid Score: {:.3f}\".format(np.mean(best_val)), \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "eMSYT7lAqMSv"
      },
      "outputs": [],
      "source": [
        "def test_evaluate():\n",
        "    final_model = GNN(config, global_size, num_tasks)\n",
        "    path = os.path.join(best_model_path, 'checkpoint.pth')\n",
        "    with open(path, 'rb') as f:\n",
        "        checkpoint = cloudpickle.load(f)\n",
        "    final_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    final_model.eval()\n",
        "    test_score = compute_score(final_model, test_dataloader, scaler, len(test_set), num_tasks)\n",
        "\n",
        "    print(\"Test Score: {:.3f}\".format(test_score), \"\\n\")\n",
        "    print(\"Execution time: {:.3f} seconds\".format(time.time() - start_time))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WprNKX-fqMSv",
        "outputId": "22d09b50-2c60-484c-889b-1e25f8903243"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 5.456 | Valid Score: 2.392\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 2.392 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 3.242 | Valid Score: 1.799\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 1.799 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 2.028 | Valid Score: 1.540\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 1.540 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 1.784 | Valid Score: 1.515\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 1.515 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 5/100 | Training Loss: 1.748 | Valid Score: 1.500\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 1.500 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 6/100 | Training Loss: 1.704 | Valid Score: 1.487\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 1.487 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 1.671 | Valid Score: 1.474\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 1.474 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 1.650 | Valid Score: 1.462\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 1.462 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 9/100 | Training Loss: 1.611 | Valid Score: 1.451\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 1.451 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 1.587 | Valid Score: 1.440\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 1.440 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 11/100 | Training Loss: 1.558 | Valid Score: 1.431\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 1.431 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 12/100 | Training Loss: 1.533 | Valid Score: 1.423\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 1.423 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 13/100 | Training Loss: 1.516 | Valid Score: 1.415\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 1.415 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 14/100 | Training Loss: 1.497 | Valid Score: 1.407\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 1.407 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 15/100 | Training Loss: 1.474 | Valid Score: 1.400\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 1.400 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 16/100 | Training Loss: 1.468 | Valid Score: 1.394\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 1.394 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 17/100 | Training Loss: 1.444 | Valid Score: 1.388\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 1.388 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 18/100 | Training Loss: 1.430 | Valid Score: 1.384\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 1.384 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 19/100 | Training Loss: 1.415 | Valid Score: 1.376\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 1.376 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 20/100 | Training Loss: 1.403 | Valid Score: 1.375\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 1.375 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 21/100 | Training Loss: 1.395 | Valid Score: 1.368\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 1.368 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 22/100 | Training Loss: 1.384 | Valid Score: 1.365\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 1.365 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 23/100 | Training Loss: 1.375 | Valid Score: 1.362\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 1.362 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 24/100 | Training Loss: 1.372 | Valid Score: 1.357\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 1.357 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 25/100 | Training Loss: 1.362 | Valid Score: 1.356\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 1.356 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 26/100 | Training Loss: 1.348 | Valid Score: 1.351\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 1.351 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 27/100 | Training Loss: 1.339 | Valid Score: 1.348\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 1.348 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 28/100 | Training Loss: 1.331 | Valid Score: 1.347\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 1.347 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 29/100 | Training Loss: 1.322 | Valid Score: 1.342\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 1.342 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 30/100 | Training Loss: 1.317 | Valid Score: 1.342\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 1.342 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 31/100 | Training Loss: 1.308 | Valid Score: 1.340\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 1.340 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 32/100 | Training Loss: 1.304 | Valid Score: 1.337\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 1.337 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 33/100 | Training Loss: 1.297 | Valid Score: 1.335\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 1.335 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 34/100 | Training Loss: 1.290 | Valid Score: 1.334\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 1.334 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 35/100 | Training Loss: 1.287 | Valid Score: 1.333\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 1.333 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 36/100 | Training Loss: 1.287 | Valid Score: 1.331\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 1.331 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 37/100 | Training Loss: 1.274 | Valid Score: 1.328\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 1.328 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 38/100 | Training Loss: 1.268 | Valid Score: 1.327\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 1.327 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 39/100 | Training Loss: 1.261 | Valid Score: 1.326\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 1.326 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 40/100 | Training Loss: 1.255 | Valid Score: 1.325\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 1.325 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 41/100 | Training Loss: 1.250 | Valid Score: 1.324\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 1.324 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 42/100 | Training Loss: 1.250 | Valid Score: 1.322\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 1.322 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 43/100 | Training Loss: 1.246 | Valid Score: 1.322\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 1.322 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 44/100 | Training Loss: 1.246 | Valid Score: 1.322\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 1.322 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 45/100 | Training Loss: 1.240 | Valid Score: 1.321\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 1.321 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 46/100 | Training Loss: 1.230 | Valid Score: 1.329\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 1.321 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 47/100 | Training Loss: 1.227 | Valid Score: 1.322\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 1.321 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 48/100 | Training Loss: 1.231 | Valid Score: 1.323\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 1.321 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 49/100 | Training Loss: 1.222 | Valid Score: 1.319\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 1.319 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 50/100 | Training Loss: 1.224 | Valid Score: 1.317\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 1.317 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 51/100 | Training Loss: 1.212 | Valid Score: 1.317\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 1.317 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 52/100 | Training Loss: 1.210 | Valid Score: 1.318\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 1.317 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 53/100 | Training Loss: 1.213 | Valid Score: 1.317\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 1.317 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 54/100 | Training Loss: 1.212 | Valid Score: 1.315\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 1.315 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 55/100 | Training Loss: 1.200 | Valid Score: 1.318\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 1.315 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 56/100 | Training Loss: 1.202 | Valid Score: 1.314\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 1.314 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 57/100 | Training Loss: 1.200 | Valid Score: 1.314\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 1.314 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 58/100 | Training Loss: 1.190 | Valid Score: 1.318\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 1.314 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 59/100 | Training Loss: 1.193 | Valid Score: 1.324\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 1.314 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 60/100 | Training Loss: 1.196 | Valid Score: 1.315\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 1.314 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 61/100 | Training Loss: 1.189 | Valid Score: 1.315\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 1.314 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 62/100 | Training Loss: 1.180 | Valid Score: 1.311\n",
            " \n",
            "Epoch: 62/100 | Best Valid Score Until Now: 1.311 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 63/100 | Training Loss: 1.189 | Valid Score: 1.312\n",
            " \n",
            "Epoch: 63/100 | Best Valid Score Until Now: 1.311 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 64/100 | Training Loss: 1.187 | Valid Score: 1.313\n",
            " \n",
            "Epoch: 64/100 | Best Valid Score Until Now: 1.311 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 65/100 | Training Loss: 1.183 | Valid Score: 1.314\n",
            " \n",
            "Epoch: 65/100 | Best Valid Score Until Now: 1.311 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 66/100 | Training Loss: 1.186 | Valid Score: 1.316\n",
            " \n",
            "Epoch: 66/100 | Best Valid Score Until Now: 1.311 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 67/100 | Training Loss: 1.171 | Valid Score: 1.314\n",
            " \n",
            "Epoch: 67/100 | Best Valid Score Until Now: 1.311 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 68/100 | Training Loss: 1.175 | Valid Score: 1.317\n",
            " \n",
            "Epoch: 68/100 | Best Valid Score Until Now: 1.311 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 69/100 | Training Loss: 1.170 | Valid Score: 1.314\n",
            " \n",
            "Epoch: 69/100 | Best Valid Score Until Now: 1.311 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 70/100 | Training Loss: 1.173 | Valid Score: 1.309\n",
            " \n",
            "Epoch: 70/100 | Best Valid Score Until Now: 1.309 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 71/100 | Training Loss: 1.172 | Valid Score: 1.309\n",
            " \n",
            "Epoch: 71/100 | Best Valid Score Until Now: 1.309 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 72/100 | Training Loss: 1.170 | Valid Score: 1.309\n",
            " \n",
            "Epoch: 72/100 | Best Valid Score Until Now: 1.309 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 73/100 | Training Loss: 1.163 | Valid Score: 1.309\n",
            " \n",
            "Epoch: 73/100 | Best Valid Score Until Now: 1.309 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 74/100 | Training Loss: 1.172 | Valid Score: 1.308\n",
            " \n",
            "Epoch: 74/100 | Best Valid Score Until Now: 1.308 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 75/100 | Training Loss: 1.160 | Valid Score: 1.312\n",
            " \n",
            "Epoch: 75/100 | Best Valid Score Until Now: 1.308 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 76/100 | Training Loss: 1.164 | Valid Score: 1.308\n",
            " \n",
            "Epoch: 76/100 | Best Valid Score Until Now: 1.308 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 77/100 | Training Loss: 1.154 | Valid Score: 1.317\n",
            " \n",
            "Epoch: 77/100 | Best Valid Score Until Now: 1.308 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 78/100 | Training Loss: 1.159 | Valid Score: 1.310\n",
            " \n",
            "Epoch: 78/100 | Best Valid Score Until Now: 1.308 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 79/100 | Training Loss: 1.156 | Valid Score: 1.308\n",
            " \n",
            "Epoch: 79/100 | Best Valid Score Until Now: 1.308 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 80/100 | Training Loss: 1.157 | Valid Score: 1.318\n",
            " \n",
            "Epoch: 80/100 | Best Valid Score Until Now: 1.308 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 81/100 | Training Loss: 1.157 | Valid Score: 1.307\n",
            " \n",
            "Epoch: 81/100 | Best Valid Score Until Now: 1.307 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 82/100 | Training Loss: 1.150 | Valid Score: 1.308\n",
            " \n",
            "Epoch: 82/100 | Best Valid Score Until Now: 1.307 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 83/100 | Training Loss: 1.156 | Valid Score: 1.306\n",
            " \n",
            "Epoch: 83/100 | Best Valid Score Until Now: 1.306 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 84/100 | Training Loss: 1.150 | Valid Score: 1.306\n",
            " \n",
            "Epoch: 84/100 | Best Valid Score Until Now: 1.306 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 85/100 | Training Loss: 1.155 | Valid Score: 1.309\n",
            " \n",
            "Epoch: 85/100 | Best Valid Score Until Now: 1.306 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 86/100 | Training Loss: 1.143 | Valid Score: 1.307\n",
            " \n",
            "Epoch: 86/100 | Best Valid Score Until Now: 1.306 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 87/100 | Training Loss: 1.160 | Valid Score: 1.306\n",
            " \n",
            "Epoch: 87/100 | Best Valid Score Until Now: 1.306 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 88/100 | Training Loss: 1.145 | Valid Score: 1.308\n",
            " \n",
            "Epoch: 88/100 | Best Valid Score Until Now: 1.306 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 89/100 | Training Loss: 1.146 | Valid Score: 1.308\n",
            " \n",
            "Epoch: 89/100 | Best Valid Score Until Now: 1.306 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 90/100 | Training Loss: 1.140 | Valid Score: 1.304\n",
            " \n",
            "Epoch: 90/100 | Best Valid Score Until Now: 1.304 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 91/100 | Training Loss: 1.143 | Valid Score: 1.304\n",
            " \n",
            "Epoch: 91/100 | Best Valid Score Until Now: 1.304 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 92/100 | Training Loss: 1.138 | Valid Score: 1.304\n",
            " \n",
            "Epoch: 92/100 | Best Valid Score Until Now: 1.304 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 93/100 | Training Loss: 1.137 | Valid Score: 1.312\n",
            " \n",
            "Epoch: 93/100 | Best Valid Score Until Now: 1.304 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 94/100 | Training Loss: 1.139 | Valid Score: 1.305\n",
            " \n",
            "Epoch: 94/100 | Best Valid Score Until Now: 1.304 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 95/100 | Training Loss: 1.137 | Valid Score: 1.307\n",
            " \n",
            "Epoch: 95/100 | Best Valid Score Until Now: 1.304 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 96/100 | Training Loss: 1.135 | Valid Score: 1.307\n",
            " \n",
            "Epoch: 96/100 | Best Valid Score Until Now: 1.304 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 97/100 | Training Loss: 1.133 | Valid Score: 1.302\n",
            " \n",
            "Epoch: 97/100 | Best Valid Score Until Now: 1.302 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 98/100 | Training Loss: 1.144 | Valid Score: 1.304\n",
            " \n",
            "Epoch: 98/100 | Best Valid Score Until Now: 1.302 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 99/100 | Training Loss: 1.131 | Valid Score: 1.316\n",
            " \n",
            "Epoch: 99/100 | Best Valid Score Until Now: 1.302 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 100/100 | Training Loss: 1.132 | Valid Score: 1.303\n",
            " \n",
            "Epoch: 100/100 | Best Valid Score Until Now: 1.302 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 1.302 \n",
            "\n",
            "Test Score: 1.372 \n",
            "\n",
            "Execution time: 117.689 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mInZ4h7VGEAp"
      },
      "source": [
        "# GCN 3 Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "D96kc9b1GG-Y"
      },
      "outputs": [],
      "source": [
        "class GNN(nn.Module):\n",
        "    def __init__(self, config, global_size=200, num_tasks=1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = GraphConv(self.node_feature_size, self.hidden_size, allow_zero_in_degree=True)\n",
        "        self.conv2 = GraphConv(self.hidden_size, self.hidden_size, allow_zero_in_degree=True)\n",
        "        self.conv3 = GraphConv(self.hidden_size, self.num_tasks, allow_zero_in_degree=True)\n",
        "\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"] = mol_dgl_graph.ndata[\"v\"][:, :self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:, :self.edge_feature_size]\n",
        "\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv3(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "g6gw-4-oGLoo"
      },
      "outputs": [],
      "source": [
        "def compute_score(model, data_loader, scaler, val_size, num_tasks=1):\n",
        "  model.eval()\n",
        "  loss_sum = nn.MSELoss(reduction='sum') # MSE with sum instead of mean, i.e., sum_i[(y_i)^2-(y'_i)^2]\n",
        "  final_loss = 0\n",
        "  state = torch.get_rng_state()\n",
        "  with torch.no_grad():\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(data_loader):\n",
        "       prediction = model(mol_dgl_graph, globals)\n",
        "       prediction = torch.tensor(scaler.inverse_transform(prediction.detach().cpu()))\n",
        "       labels = torch.tensor(scaler.inverse_transform(labels.cpu()))\n",
        "       loss = loss_sum(prediction, labels)\n",
        "       final_loss += loss.item()\n",
        "\n",
        "    final_loss /= val_size\n",
        "    final_loss = math.sqrt(final_loss)\n",
        "\n",
        "  return final_loss / num_tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "bt-VXcG1GLoo"
      },
      "outputs": [],
      "source": [
        "def loss_func(output, label, mask, num_tasks):\n",
        "    pos_weight = torch.ones((1, num_tasks))\n",
        "    pos_weight\n",
        "    criterion = nn.MSELoss(reduction='none')\n",
        "    loss = mask*criterion(output,label)\n",
        "    loss = loss.sum() / mask.sum()\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "cHp_w94NGLoo"
      },
      "outputs": [],
      "source": [
        "def train_epoch(train_dataloader, model, optimizer):\n",
        "    epoch_train_loss = 0\n",
        "    iterations = 0\n",
        "    model.train() \n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(train_dataloader):\n",
        "        prediction = model(mol_dgl_graph, globals)\n",
        "        loss_train = loss_func(prediction, labels, masks, num_tasks)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_loss += loss_train.detach().item()\n",
        "        iterations += 1\n",
        "    epoch_train_loss /= iterations\n",
        "    return epoch_train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "EzC2XMTvGLop"
      },
      "outputs": [],
      "source": [
        "def train_evaluate():\n",
        "\n",
        "    model = GNN(config, global_size, num_tasks)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "    best_val = 100000\n",
        "    patience_count = 1\n",
        "    epoch = 1\n",
        "\n",
        "    while epoch <= num_epochs:\n",
        "        if patience_count <= patience:\n",
        "            model.train()\n",
        "            loss_train = train_epoch(train_dataloader, model, optimizer)\n",
        "            model.eval()\n",
        "            score_val = compute_score(model, val_dataloader,scaler, len(val_set), num_tasks)\n",
        "            if score_val < best_val:\n",
        "                best_val = score_val\n",
        "                print(\"Save checkpoint\")\n",
        "                path = os.path.join(checkpoint_path, 'checkpoint.pth')\n",
        "                dict_checkpoint = {\"score_val\": score_val}\n",
        "                dict_checkpoint.update({\"model_state_dict\": model.state_dict(), \"optimizer_state\": optimizer.state_dict()})\n",
        "                with open(path, \"wb\") as outputfile:\n",
        "                    cloudpickle.dump(dict_checkpoint, outputfile)\n",
        "                patience_count = 1\n",
        "            else:\n",
        "                print(\"Patience\", patience_count)\n",
        "                patience_count += 1\n",
        "\n",
        "            print(\"Epoch: {}/{} | Training Loss: {:.3f} | Valid Score: {:.3f}\".format(\n",
        "            epoch, num_epochs, loss_train, score_val))\n",
        "\n",
        "            print(\" \")\n",
        "            print(\"Epoch: {}/{} | Best Valid Score Until Now: {:.3f}\".format(epoch, num_epochs, best_val), \"\\n\")\n",
        "        epoch += 1\n",
        "\n",
        "    \n",
        "    shutil.rmtree(best_model_path, ignore_errors=True)\n",
        "    shutil.copytree(checkpoint_path, best_model_path)\n",
        "\n",
        "    print(\"Final results:\")\n",
        "    print(\"Average Valid Score: {:.3f}\".format(np.mean(best_val)), \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "pby56tsGGLop"
      },
      "outputs": [],
      "source": [
        "def test_evaluate():\n",
        "    final_model = GNN(config, global_size, num_tasks)\n",
        "    path = os.path.join(best_model_path, 'checkpoint.pth')\n",
        "    with open(path, 'rb') as f:\n",
        "        checkpoint = cloudpickle.load(f)\n",
        "    final_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    final_model.eval()\n",
        "    test_score = compute_score(final_model, test_dataloader, scaler, len(test_set), num_tasks)\n",
        "\n",
        "    print(\"Test Score: {:.3f}\".format(test_score), \"\\n\")\n",
        "    print(\"Execution time: {:.3f} seconds\".format(time.time() - start_time))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TW-WXwetGLop",
        "outputId": "a71eeb72-4d88-4837-8b09-bb3ed0b88ab3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 6.726 | Valid Score: 2.726\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 2.726 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 4.331 | Valid Score: 2.085\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 2.085 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 2.483 | Valid Score: 1.598\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 1.598 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 1.808 | Valid Score: 1.514\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 1.514 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 5/100 | Training Loss: 1.747 | Valid Score: 1.501\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 1.501 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 6/100 | Training Loss: 1.701 | Valid Score: 1.487\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 1.487 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 1.679 | Valid Score: 1.474\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 1.474 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 1.637 | Valid Score: 1.462\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 1.462 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 9/100 | Training Loss: 1.610 | Valid Score: 1.451\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 1.451 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 1.587 | Valid Score: 1.440\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 1.440 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 11/100 | Training Loss: 1.558 | Valid Score: 1.431\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 1.431 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 12/100 | Training Loss: 1.537 | Valid Score: 1.422\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 1.422 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 13/100 | Training Loss: 1.517 | Valid Score: 1.414\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 1.414 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 14/100 | Training Loss: 1.489 | Valid Score: 1.408\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 1.408 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 15/100 | Training Loss: 1.473 | Valid Score: 1.402\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 1.402 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 16/100 | Training Loss: 1.457 | Valid Score: 1.396\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 1.396 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 17/100 | Training Loss: 1.446 | Valid Score: 1.391\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 1.391 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 18/100 | Training Loss: 1.433 | Valid Score: 1.385\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 1.385 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 19/100 | Training Loss: 1.422 | Valid Score: 1.382\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 1.382 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 20/100 | Training Loss: 1.409 | Valid Score: 1.377\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 1.377 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 21/100 | Training Loss: 1.396 | Valid Score: 1.373\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 1.373 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 22/100 | Training Loss: 1.394 | Valid Score: 1.370\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 1.370 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 23/100 | Training Loss: 1.386 | Valid Score: 1.369\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 1.369 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 24/100 | Training Loss: 1.374 | Valid Score: 1.366\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 1.366 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 25/100 | Training Loss: 1.363 | Valid Score: 1.361\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 1.361 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 26/100 | Training Loss: 1.360 | Valid Score: 1.357\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 1.357 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 27/100 | Training Loss: 1.346 | Valid Score: 1.353\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 1.353 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 28/100 | Training Loss: 1.347 | Valid Score: 1.355\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 1.353 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 29/100 | Training Loss: 1.342 | Valid Score: 1.351\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 1.351 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 30/100 | Training Loss: 1.327 | Valid Score: 1.346\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 1.346 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 31/100 | Training Loss: 1.324 | Valid Score: 1.343\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 1.343 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 32/100 | Training Loss: 1.327 | Valid Score: 1.341\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 1.341 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 33/100 | Training Loss: 1.311 | Valid Score: 1.338\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 1.338 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 34/100 | Training Loss: 1.308 | Valid Score: 1.341\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 1.338 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 35/100 | Training Loss: 1.294 | Valid Score: 1.336\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 1.336 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 36/100 | Training Loss: 1.300 | Valid Score: 1.334\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 1.334 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 37/100 | Training Loss: 1.290 | Valid Score: 1.332\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 1.332 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 38/100 | Training Loss: 1.287 | Valid Score: 1.330\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 1.330 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 39/100 | Training Loss: 1.282 | Valid Score: 1.333\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 1.330 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 40/100 | Training Loss: 1.281 | Valid Score: 1.328\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 1.328 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 41/100 | Training Loss: 1.269 | Valid Score: 1.327\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 1.327 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 42/100 | Training Loss: 1.274 | Valid Score: 1.331\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 1.327 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 43/100 | Training Loss: 1.261 | Valid Score: 1.325\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 1.325 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 44/100 | Training Loss: 1.256 | Valid Score: 1.324\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 1.324 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 45/100 | Training Loss: 1.264 | Valid Score: 1.324\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 1.324 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 46/100 | Training Loss: 1.252 | Valid Score: 1.322\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 1.322 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 47/100 | Training Loss: 1.251 | Valid Score: 1.321\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 1.321 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 48/100 | Training Loss: 1.254 | Valid Score: 1.325\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 1.321 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 49/100 | Training Loss: 1.241 | Valid Score: 1.320\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 1.320 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 50/100 | Training Loss: 1.242 | Valid Score: 1.319\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 1.319 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 51/100 | Training Loss: 1.234 | Valid Score: 1.320\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 1.319 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 52/100 | Training Loss: 1.228 | Valid Score: 1.319\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 1.319 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 53/100 | Training Loss: 1.233 | Valid Score: 1.330\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 1.319 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 54/100 | Training Loss: 1.226 | Valid Score: 1.317\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 1.317 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 55/100 | Training Loss: 1.226 | Valid Score: 1.318\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 1.317 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 56/100 | Training Loss: 1.219 | Valid Score: 1.319\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 1.317 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 57/100 | Training Loss: 1.222 | Valid Score: 1.315\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 1.315 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 58/100 | Training Loss: 1.214 | Valid Score: 1.318\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 1.315 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 59/100 | Training Loss: 1.223 | Valid Score: 1.313\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 1.313 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 60/100 | Training Loss: 1.211 | Valid Score: 1.315\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 1.313 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 61/100 | Training Loss: 1.215 | Valid Score: 1.322\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 1.313 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 62/100 | Training Loss: 1.209 | Valid Score: 1.314\n",
            " \n",
            "Epoch: 62/100 | Best Valid Score Until Now: 1.313 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 63/100 | Training Loss: 1.208 | Valid Score: 1.313\n",
            " \n",
            "Epoch: 63/100 | Best Valid Score Until Now: 1.313 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 64/100 | Training Loss: 1.203 | Valid Score: 1.311\n",
            " \n",
            "Epoch: 64/100 | Best Valid Score Until Now: 1.311 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 65/100 | Training Loss: 1.204 | Valid Score: 1.317\n",
            " \n",
            "Epoch: 65/100 | Best Valid Score Until Now: 1.311 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 66/100 | Training Loss: 1.200 | Valid Score: 1.312\n",
            " \n",
            "Epoch: 66/100 | Best Valid Score Until Now: 1.311 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 67/100 | Training Loss: 1.197 | Valid Score: 1.310\n",
            " \n",
            "Epoch: 67/100 | Best Valid Score Until Now: 1.310 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 68/100 | Training Loss: 1.198 | Valid Score: 1.310\n",
            " \n",
            "Epoch: 68/100 | Best Valid Score Until Now: 1.310 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 69/100 | Training Loss: 1.195 | Valid Score: 1.308\n",
            " \n",
            "Epoch: 69/100 | Best Valid Score Until Now: 1.308 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 70/100 | Training Loss: 1.191 | Valid Score: 1.309\n",
            " \n",
            "Epoch: 70/100 | Best Valid Score Until Now: 1.308 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 71/100 | Training Loss: 1.186 | Valid Score: 1.307\n",
            " \n",
            "Epoch: 71/100 | Best Valid Score Until Now: 1.307 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 72/100 | Training Loss: 1.189 | Valid Score: 1.306\n",
            " \n",
            "Epoch: 72/100 | Best Valid Score Until Now: 1.306 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 73/100 | Training Loss: 1.184 | Valid Score: 1.306\n",
            " \n",
            "Epoch: 73/100 | Best Valid Score Until Now: 1.306 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 74/100 | Training Loss: 1.179 | Valid Score: 1.309\n",
            " \n",
            "Epoch: 74/100 | Best Valid Score Until Now: 1.306 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 75/100 | Training Loss: 1.184 | Valid Score: 1.306\n",
            " \n",
            "Epoch: 75/100 | Best Valid Score Until Now: 1.306 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 76/100 | Training Loss: 1.178 | Valid Score: 1.308\n",
            " \n",
            "Epoch: 76/100 | Best Valid Score Until Now: 1.306 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 77/100 | Training Loss: 1.182 | Valid Score: 1.305\n",
            " \n",
            "Epoch: 77/100 | Best Valid Score Until Now: 1.305 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 78/100 | Training Loss: 1.173 | Valid Score: 1.305\n",
            " \n",
            "Epoch: 78/100 | Best Valid Score Until Now: 1.305 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 79/100 | Training Loss: 1.171 | Valid Score: 1.304\n",
            " \n",
            "Epoch: 79/100 | Best Valid Score Until Now: 1.304 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 80/100 | Training Loss: 1.171 | Valid Score: 1.303\n",
            " \n",
            "Epoch: 80/100 | Best Valid Score Until Now: 1.303 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 81/100 | Training Loss: 1.170 | Valid Score: 1.308\n",
            " \n",
            "Epoch: 81/100 | Best Valid Score Until Now: 1.303 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 82/100 | Training Loss: 1.170 | Valid Score: 1.303\n",
            " \n",
            "Epoch: 82/100 | Best Valid Score Until Now: 1.303 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 83/100 | Training Loss: 1.175 | Valid Score: 1.303\n",
            " \n",
            "Epoch: 83/100 | Best Valid Score Until Now: 1.303 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 84/100 | Training Loss: 1.167 | Valid Score: 1.304\n",
            " \n",
            "Epoch: 84/100 | Best Valid Score Until Now: 1.303 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 85/100 | Training Loss: 1.170 | Valid Score: 1.302\n",
            " \n",
            "Epoch: 85/100 | Best Valid Score Until Now: 1.302 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 86/100 | Training Loss: 1.166 | Valid Score: 1.309\n",
            " \n",
            "Epoch: 86/100 | Best Valid Score Until Now: 1.302 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 87/100 | Training Loss: 1.172 | Valid Score: 1.300\n",
            " \n",
            "Epoch: 87/100 | Best Valid Score Until Now: 1.300 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 88/100 | Training Loss: 1.163 | Valid Score: 1.300\n",
            " \n",
            "Epoch: 88/100 | Best Valid Score Until Now: 1.300 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 89/100 | Training Loss: 1.158 | Valid Score: 1.299\n",
            " \n",
            "Epoch: 89/100 | Best Valid Score Until Now: 1.299 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 90/100 | Training Loss: 1.153 | Valid Score: 1.300\n",
            " \n",
            "Epoch: 90/100 | Best Valid Score Until Now: 1.299 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 91/100 | Training Loss: 1.156 | Valid Score: 1.298\n",
            " \n",
            "Epoch: 91/100 | Best Valid Score Until Now: 1.298 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 92/100 | Training Loss: 1.154 | Valid Score: 1.297\n",
            " \n",
            "Epoch: 92/100 | Best Valid Score Until Now: 1.297 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 93/100 | Training Loss: 1.153 | Valid Score: 1.307\n",
            " \n",
            "Epoch: 93/100 | Best Valid Score Until Now: 1.297 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 94/100 | Training Loss: 1.160 | Valid Score: 1.300\n",
            " \n",
            "Epoch: 94/100 | Best Valid Score Until Now: 1.297 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 95/100 | Training Loss: 1.149 | Valid Score: 1.303\n",
            " \n",
            "Epoch: 95/100 | Best Valid Score Until Now: 1.297 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 96/100 | Training Loss: 1.154 | Valid Score: 1.303\n",
            " \n",
            "Epoch: 96/100 | Best Valid Score Until Now: 1.297 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 97/100 | Training Loss: 1.145 | Valid Score: 1.298\n",
            " \n",
            "Epoch: 97/100 | Best Valid Score Until Now: 1.297 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 98/100 | Training Loss: 1.143 | Valid Score: 1.296\n",
            " \n",
            "Epoch: 98/100 | Best Valid Score Until Now: 1.296 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 99/100 | Training Loss: 1.151 | Valid Score: 1.296\n",
            " \n",
            "Epoch: 99/100 | Best Valid Score Until Now: 1.296 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 100/100 | Training Loss: 1.148 | Valid Score: 1.298\n",
            " \n",
            "Epoch: 100/100 | Best Valid Score Until Now: 1.296 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 1.296 \n",
            "\n",
            "Test Score: 1.370 \n",
            "\n",
            "Execution time: 111.987 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tLj_lcUGHQo"
      },
      "source": [
        "# GraphSAGE 2 Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "8NEqbKEvG205"
      },
      "outputs": [],
      "source": [
        "class GNN(nn.Module):\n",
        "    def __init__(self, config, global_size = 200, num_tasks = 1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = SAGEConv(self.node_feature_size, self.hidden_size,aggregator_type='mean')\n",
        "        self.conv2 = SAGEConv(self.hidden_size, self.num_tasks, aggregator_type='mean')\n",
        "\n",
        "    # def forward(self, g, in_feat):\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"]= mol_dgl_graph.ndata[\"v\"][:,:self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:,:self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "J0uyl5_iHDEh"
      },
      "outputs": [],
      "source": [
        "def compute_score(model, data_loader, scaler, val_size, num_tasks=1):\n",
        "  model.eval()\n",
        "  loss_sum = nn.MSELoss(reduction='sum') # MSE with sum instead of mean, i.e., sum_i[(y_i)^2-(y'_i)^2]\n",
        "  final_loss = 0\n",
        "  state = torch.get_rng_state()\n",
        "  with torch.no_grad():\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(data_loader):\n",
        "       prediction = model(mol_dgl_graph, globals)\n",
        "       prediction = torch.tensor(scaler.inverse_transform(prediction.detach().cpu()))\n",
        "       labels = torch.tensor(scaler.inverse_transform(labels.cpu()))\n",
        "       loss = loss_sum(prediction, labels)\n",
        "       final_loss += loss.item()\n",
        "\n",
        "    final_loss /= val_size\n",
        "    final_loss = math.sqrt(final_loss)\n",
        "\n",
        "  return final_loss / num_tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "pwA8cCKyHDEi"
      },
      "outputs": [],
      "source": [
        "def loss_func(output, label, mask, num_tasks):\n",
        "    pos_weight = torch.ones((1, num_tasks))\n",
        "    pos_weight\n",
        "    criterion = nn.MSELoss(reduction='none')\n",
        "    loss = mask*criterion(output,label)\n",
        "    loss = loss.sum() / mask.sum()\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "1B2vVS4_HDEi"
      },
      "outputs": [],
      "source": [
        "def train_epoch(train_dataloader, model, optimizer):\n",
        "    epoch_train_loss = 0\n",
        "    iterations = 0\n",
        "    model.train() \n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(train_dataloader):\n",
        "        prediction = model(mol_dgl_graph, globals)\n",
        "        loss_train = loss_func(prediction, labels, masks, num_tasks)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_loss += loss_train.detach().item()\n",
        "        iterations += 1\n",
        "    epoch_train_loss /= iterations\n",
        "    return epoch_train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "FcqinIWFHDEi"
      },
      "outputs": [],
      "source": [
        "def train_evaluate():\n",
        "\n",
        "    model = GNN(config, global_size, num_tasks)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "    best_val = 100000\n",
        "    patience_count = 1\n",
        "    epoch = 1\n",
        "\n",
        "    while epoch <= num_epochs:\n",
        "        if patience_count <= patience:\n",
        "            model.train()\n",
        "            loss_train = train_epoch(train_dataloader, model, optimizer)\n",
        "            model.eval()\n",
        "            score_val = compute_score(model, val_dataloader,scaler, len(val_set), num_tasks)\n",
        "            if score_val < best_val:\n",
        "                best_val = score_val\n",
        "                print(\"Save checkpoint\")\n",
        "                path = os.path.join(checkpoint_path, 'checkpoint.pth')\n",
        "                dict_checkpoint = {\"score_val\": score_val}\n",
        "                dict_checkpoint.update({\"model_state_dict\": model.state_dict(), \"optimizer_state\": optimizer.state_dict()})\n",
        "                with open(path, \"wb\") as outputfile:\n",
        "                    cloudpickle.dump(dict_checkpoint, outputfile)\n",
        "                patience_count = 1\n",
        "            else:\n",
        "                print(\"Patience\", patience_count)\n",
        "                patience_count += 1\n",
        "\n",
        "            print(\"Epoch: {}/{} | Training Loss: {:.3f} | Valid Score: {:.3f}\".format(\n",
        "            epoch, num_epochs, loss_train, score_val))\n",
        "\n",
        "            print(\" \")\n",
        "            print(\"Epoch: {}/{} | Best Valid Score Until Now: {:.3f}\".format(epoch, num_epochs, best_val), \"\\n\")\n",
        "        epoch += 1\n",
        "\n",
        "    \n",
        "    shutil.rmtree(best_model_path, ignore_errors=True)\n",
        "    shutil.copytree(checkpoint_path, best_model_path)\n",
        "\n",
        "    print(\"Final results:\")\n",
        "    print(\"Average Valid Score: {:.3f}\".format(np.mean(best_val)), \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "YewrYxgCHDEi"
      },
      "outputs": [],
      "source": [
        "def test_evaluate():\n",
        "    final_model = GNN(config, global_size, num_tasks)\n",
        "    path = os.path.join(best_model_path, 'checkpoint.pth')\n",
        "    with open(path, 'rb') as f:\n",
        "        checkpoint = cloudpickle.load(f)\n",
        "    final_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    final_model.eval()\n",
        "    test_score = compute_score(final_model, test_dataloader, scaler, len(test_set), num_tasks)\n",
        "\n",
        "    print(\"Test Score: {:.3f}\".format(test_score), \"\\n\")\n",
        "    print(\"Execution time: {:.3f} seconds\".format(time.time() - start_time))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nmxP5CvHDEi",
        "outputId": "6572e01c-e510-4200-97fa-15b439fc5e85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 4.683 | Valid Score: 2.003\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 2.003 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 2.308 | Valid Score: 1.608\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 1.608 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 1.851 | Valid Score: 1.543\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 1.543 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 1.761 | Valid Score: 1.520\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 1.520 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 5/100 | Training Loss: 1.698 | Valid Score: 1.499\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 1.499 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 6/100 | Training Loss: 1.656 | Valid Score: 1.482\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 1.482 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 1.609 | Valid Score: 1.466\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 1.466 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 1.578 | Valid Score: 1.453\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 1.453 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 9/100 | Training Loss: 1.538 | Valid Score: 1.441\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 1.441 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 1.514 | Valid Score: 1.432\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 1.432 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 11/100 | Training Loss: 1.491 | Valid Score: 1.421\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 1.421 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 12/100 | Training Loss: 1.472 | Valid Score: 1.411\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 1.411 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 13/100 | Training Loss: 1.446 | Valid Score: 1.404\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 1.404 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 14/100 | Training Loss: 1.426 | Valid Score: 1.397\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 1.397 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 15/100 | Training Loss: 1.411 | Valid Score: 1.391\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 1.391 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 16/100 | Training Loss: 1.395 | Valid Score: 1.385\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 1.385 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 17/100 | Training Loss: 1.377 | Valid Score: 1.380\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 1.380 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 18/100 | Training Loss: 1.365 | Valid Score: 1.372\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 1.372 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 19/100 | Training Loss: 1.357 | Valid Score: 1.367\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 1.367 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 20/100 | Training Loss: 1.345 | Valid Score: 1.364\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 1.364 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 21/100 | Training Loss: 1.333 | Valid Score: 1.358\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 1.358 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 22/100 | Training Loss: 1.318 | Valid Score: 1.353\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 1.353 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 23/100 | Training Loss: 1.306 | Valid Score: 1.350\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 1.350 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 24/100 | Training Loss: 1.304 | Valid Score: 1.344\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 1.344 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 25/100 | Training Loss: 1.292 | Valid Score: 1.340\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 1.340 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 26/100 | Training Loss: 1.284 | Valid Score: 1.339\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 1.339 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 27/100 | Training Loss: 1.280 | Valid Score: 1.333\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 1.333 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 28/100 | Training Loss: 1.269 | Valid Score: 1.329\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 1.329 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 29/100 | Training Loss: 1.267 | Valid Score: 1.326\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 1.326 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 30/100 | Training Loss: 1.255 | Valid Score: 1.324\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 1.324 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 31/100 | Training Loss: 1.250 | Valid Score: 1.322\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 1.322 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 32/100 | Training Loss: 1.238 | Valid Score: 1.318\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 1.318 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 33/100 | Training Loss: 1.232 | Valid Score: 1.313\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 1.313 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 34/100 | Training Loss: 1.225 | Valid Score: 1.311\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 1.311 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 35/100 | Training Loss: 1.220 | Valid Score: 1.308\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 1.308 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 36/100 | Training Loss: 1.222 | Valid Score: 1.305\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 1.305 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 37/100 | Training Loss: 1.214 | Valid Score: 1.304\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 1.304 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 38/100 | Training Loss: 1.207 | Valid Score: 1.301\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 1.301 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 39/100 | Training Loss: 1.205 | Valid Score: 1.299\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 1.299 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 40/100 | Training Loss: 1.192 | Valid Score: 1.296\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 1.296 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 41/100 | Training Loss: 1.192 | Valid Score: 1.297\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 1.296 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 42/100 | Training Loss: 1.192 | Valid Score: 1.293\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 1.293 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 43/100 | Training Loss: 1.184 | Valid Score: 1.291\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 1.291 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 44/100 | Training Loss: 1.178 | Valid Score: 1.289\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 1.289 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 45/100 | Training Loss: 1.182 | Valid Score: 1.287\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 1.287 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 46/100 | Training Loss: 1.171 | Valid Score: 1.285\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 1.285 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 47/100 | Training Loss: 1.171 | Valid Score: 1.287\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 1.285 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 48/100 | Training Loss: 1.165 | Valid Score: 1.282\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 1.282 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 49/100 | Training Loss: 1.162 | Valid Score: 1.281\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 1.281 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 50/100 | Training Loss: 1.160 | Valid Score: 1.280\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 1.280 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 51/100 | Training Loss: 1.155 | Valid Score: 1.277\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 1.277 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 52/100 | Training Loss: 1.152 | Valid Score: 1.277\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 1.277 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 53/100 | Training Loss: 1.146 | Valid Score: 1.275\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 1.275 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 54/100 | Training Loss: 1.148 | Valid Score: 1.275\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 1.275 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 55/100 | Training Loss: 1.148 | Valid Score: 1.274\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 1.274 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 56/100 | Training Loss: 1.136 | Valid Score: 1.271\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 1.271 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 57/100 | Training Loss: 1.144 | Valid Score: 1.270\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 1.270 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 58/100 | Training Loss: 1.140 | Valid Score: 1.269\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 1.269 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 59/100 | Training Loss: 1.133 | Valid Score: 1.267\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 1.267 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 60/100 | Training Loss: 1.131 | Valid Score: 1.267\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 1.267 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 61/100 | Training Loss: 1.126 | Valid Score: 1.266\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 1.266 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 62/100 | Training Loss: 1.123 | Valid Score: 1.264\n",
            " \n",
            "Epoch: 62/100 | Best Valid Score Until Now: 1.264 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 63/100 | Training Loss: 1.119 | Valid Score: 1.264\n",
            " \n",
            "Epoch: 63/100 | Best Valid Score Until Now: 1.264 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 64/100 | Training Loss: 1.114 | Valid Score: 1.262\n",
            " \n",
            "Epoch: 64/100 | Best Valid Score Until Now: 1.262 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 65/100 | Training Loss: 1.113 | Valid Score: 1.263\n",
            " \n",
            "Epoch: 65/100 | Best Valid Score Until Now: 1.262 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 66/100 | Training Loss: 1.112 | Valid Score: 1.265\n",
            " \n",
            "Epoch: 66/100 | Best Valid Score Until Now: 1.262 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 67/100 | Training Loss: 1.115 | Valid Score: 1.258\n",
            " \n",
            "Epoch: 67/100 | Best Valid Score Until Now: 1.258 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 68/100 | Training Loss: 1.115 | Valid Score: 1.257\n",
            " \n",
            "Epoch: 68/100 | Best Valid Score Until Now: 1.257 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 69/100 | Training Loss: 1.112 | Valid Score: 1.258\n",
            " \n",
            "Epoch: 69/100 | Best Valid Score Until Now: 1.257 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 70/100 | Training Loss: 1.108 | Valid Score: 1.255\n",
            " \n",
            "Epoch: 70/100 | Best Valid Score Until Now: 1.255 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 71/100 | Training Loss: 1.099 | Valid Score: 1.255\n",
            " \n",
            "Epoch: 71/100 | Best Valid Score Until Now: 1.255 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 72/100 | Training Loss: 1.100 | Valid Score: 1.253\n",
            " \n",
            "Epoch: 72/100 | Best Valid Score Until Now: 1.253 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 73/100 | Training Loss: 1.098 | Valid Score: 1.252\n",
            " \n",
            "Epoch: 73/100 | Best Valid Score Until Now: 1.252 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 74/100 | Training Loss: 1.098 | Valid Score: 1.252\n",
            " \n",
            "Epoch: 74/100 | Best Valid Score Until Now: 1.252 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 75/100 | Training Loss: 1.097 | Valid Score: 1.251\n",
            " \n",
            "Epoch: 75/100 | Best Valid Score Until Now: 1.251 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 76/100 | Training Loss: 1.092 | Valid Score: 1.250\n",
            " \n",
            "Epoch: 76/100 | Best Valid Score Until Now: 1.250 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 77/100 | Training Loss: 1.091 | Valid Score: 1.249\n",
            " \n",
            "Epoch: 77/100 | Best Valid Score Until Now: 1.249 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 78/100 | Training Loss: 1.087 | Valid Score: 1.248\n",
            " \n",
            "Epoch: 78/100 | Best Valid Score Until Now: 1.248 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 79/100 | Training Loss: 1.088 | Valid Score: 1.247\n",
            " \n",
            "Epoch: 79/100 | Best Valid Score Until Now: 1.247 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 80/100 | Training Loss: 1.086 | Valid Score: 1.246\n",
            " \n",
            "Epoch: 80/100 | Best Valid Score Until Now: 1.246 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 81/100 | Training Loss: 1.079 | Valid Score: 1.246\n",
            " \n",
            "Epoch: 81/100 | Best Valid Score Until Now: 1.246 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 82/100 | Training Loss: 1.079 | Valid Score: 1.245\n",
            " \n",
            "Epoch: 82/100 | Best Valid Score Until Now: 1.245 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 83/100 | Training Loss: 1.084 | Valid Score: 1.245\n",
            " \n",
            "Epoch: 83/100 | Best Valid Score Until Now: 1.245 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 84/100 | Training Loss: 1.076 | Valid Score: 1.244\n",
            " \n",
            "Epoch: 84/100 | Best Valid Score Until Now: 1.244 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 85/100 | Training Loss: 1.074 | Valid Score: 1.243\n",
            " \n",
            "Epoch: 85/100 | Best Valid Score Until Now: 1.243 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 86/100 | Training Loss: 1.075 | Valid Score: 1.244\n",
            " \n",
            "Epoch: 86/100 | Best Valid Score Until Now: 1.243 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 87/100 | Training Loss: 1.071 | Valid Score: 1.246\n",
            " \n",
            "Epoch: 87/100 | Best Valid Score Until Now: 1.243 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 88/100 | Training Loss: 1.073 | Valid Score: 1.241\n",
            " \n",
            "Epoch: 88/100 | Best Valid Score Until Now: 1.241 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 89/100 | Training Loss: 1.071 | Valid Score: 1.240\n",
            " \n",
            "Epoch: 89/100 | Best Valid Score Until Now: 1.240 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 90/100 | Training Loss: 1.065 | Valid Score: 1.243\n",
            " \n",
            "Epoch: 90/100 | Best Valid Score Until Now: 1.240 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 91/100 | Training Loss: 1.067 | Valid Score: 1.242\n",
            " \n",
            "Epoch: 91/100 | Best Valid Score Until Now: 1.240 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 92/100 | Training Loss: 1.064 | Valid Score: 1.240\n",
            " \n",
            "Epoch: 92/100 | Best Valid Score Until Now: 1.240 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 93/100 | Training Loss: 1.064 | Valid Score: 1.238\n",
            " \n",
            "Epoch: 93/100 | Best Valid Score Until Now: 1.238 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 94/100 | Training Loss: 1.056 | Valid Score: 1.240\n",
            " \n",
            "Epoch: 94/100 | Best Valid Score Until Now: 1.238 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 95/100 | Training Loss: 1.056 | Valid Score: 1.237\n",
            " \n",
            "Epoch: 95/100 | Best Valid Score Until Now: 1.237 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 96/100 | Training Loss: 1.057 | Valid Score: 1.239\n",
            " \n",
            "Epoch: 96/100 | Best Valid Score Until Now: 1.237 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 97/100 | Training Loss: 1.055 | Valid Score: 1.236\n",
            " \n",
            "Epoch: 97/100 | Best Valid Score Until Now: 1.236 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 98/100 | Training Loss: 1.054 | Valid Score: 1.235\n",
            " \n",
            "Epoch: 98/100 | Best Valid Score Until Now: 1.235 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 99/100 | Training Loss: 1.052 | Valid Score: 1.235\n",
            " \n",
            "Epoch: 99/100 | Best Valid Score Until Now: 1.235 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 100/100 | Training Loss: 1.045 | Valid Score: 1.237\n",
            " \n",
            "Epoch: 100/100 | Best Valid Score Until Now: 1.235 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 1.235 \n",
            "\n",
            "Test Score: 1.323 \n",
            "\n",
            "Execution time: 113.391 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOu1vsLkG3Io"
      },
      "source": [
        "# GraphSAGE 3 Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "NWFh_9dT1Eos"
      },
      "outputs": [],
      "source": [
        "class GNN(nn.Module):\n",
        "    def __init__(self, config, global_size=200, num_tasks=1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = SAGEConv(self.node_feature_size, self.hidden_size,aggregator_type='mean')\n",
        "        self.conv2 = SAGEConv(self.hidden_size, self.hidden_size,aggregator_type='mean')\n",
        "        self.conv3 = SAGEConv(self.hidden_size, self.num_tasks,aggregator_type='mean')\n",
        "\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"] = mol_dgl_graph.ndata[\"v\"][:, :self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:, :self.edge_feature_size]\n",
        "\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv3(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "gJe2woCfH4Jp"
      },
      "outputs": [],
      "source": [
        "def compute_score(model, data_loader, scaler, val_size, num_tasks=1):\n",
        "  model.eval()\n",
        "  loss_sum = nn.MSELoss(reduction='sum') # MSE with sum instead of mean, i.e., sum_i[(y_i)^2-(y'_i)^2]\n",
        "  final_loss = 0\n",
        "  state = torch.get_rng_state()\n",
        "  with torch.no_grad():\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(data_loader):\n",
        "       prediction = model(mol_dgl_graph, globals)\n",
        "       prediction = torch.tensor(scaler.inverse_transform(prediction.detach().cpu()))\n",
        "       labels = torch.tensor(scaler.inverse_transform(labels.cpu()))\n",
        "       loss = loss_sum(prediction, labels)\n",
        "       final_loss += loss.item()\n",
        "\n",
        "    final_loss /= val_size\n",
        "    final_loss = math.sqrt(final_loss)\n",
        "\n",
        "  return final_loss / num_tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "iyuF-2BiH4Jp"
      },
      "outputs": [],
      "source": [
        "def loss_func(output, label, mask, num_tasks):\n",
        "    pos_weight = torch.ones((1, num_tasks))\n",
        "    pos_weight\n",
        "    criterion = nn.MSELoss(reduction='none')\n",
        "    loss = mask*criterion(output,label)\n",
        "    loss = loss.sum() / mask.sum()\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "1pai-jJyH4Jp"
      },
      "outputs": [],
      "source": [
        "def train_epoch(train_dataloader, model, optimizer):\n",
        "    epoch_train_loss = 0\n",
        "    iterations = 0\n",
        "    model.train() \n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(train_dataloader):\n",
        "        prediction = model(mol_dgl_graph, globals)\n",
        "        loss_train = loss_func(prediction, labels, masks, num_tasks)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_loss += loss_train.detach().item()\n",
        "        iterations += 1\n",
        "    epoch_train_loss /= iterations\n",
        "    return epoch_train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "B_5Qt4m8H4Jq"
      },
      "outputs": [],
      "source": [
        "def train_evaluate():\n",
        "\n",
        "    model = GNN(config, global_size, num_tasks)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "    best_val = 100000\n",
        "    patience_count = 1\n",
        "    epoch = 1\n",
        "\n",
        "    while epoch <= num_epochs:\n",
        "        if patience_count <= patience:\n",
        "            model.train()\n",
        "            loss_train = train_epoch(train_dataloader, model, optimizer)\n",
        "            model.eval()\n",
        "            score_val = compute_score(model, val_dataloader,scaler, len(val_set), num_tasks)\n",
        "            if score_val < best_val:\n",
        "                best_val = score_val\n",
        "                print(\"Save checkpoint\")\n",
        "                path = os.path.join(checkpoint_path, 'checkpoint.pth')\n",
        "                dict_checkpoint = {\"score_val\": score_val}\n",
        "                dict_checkpoint.update({\"model_state_dict\": model.state_dict(), \"optimizer_state\": optimizer.state_dict()})\n",
        "                with open(path, \"wb\") as outputfile:\n",
        "                    cloudpickle.dump(dict_checkpoint, outputfile)\n",
        "                patience_count = 1\n",
        "            else:\n",
        "                print(\"Patience\", patience_count)\n",
        "                patience_count += 1\n",
        "\n",
        "            print(\"Epoch: {}/{} | Training Loss: {:.3f} | Valid Score: {:.3f}\".format(\n",
        "            epoch, num_epochs, loss_train, score_val))\n",
        "\n",
        "            print(\" \")\n",
        "            print(\"Epoch: {}/{} | Best Valid Score Until Now: {:.3f}\".format(epoch, num_epochs, best_val), \"\\n\")\n",
        "        epoch += 1\n",
        "\n",
        "    \n",
        "    shutil.rmtree(best_model_path, ignore_errors=True)\n",
        "    shutil.copytree(checkpoint_path, best_model_path)\n",
        "\n",
        "    print(\"Final results:\")\n",
        "    print(\"Average Valid Score: {:.3f}\".format(np.mean(best_val)), \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "S5zCMmqMH4Jq"
      },
      "outputs": [],
      "source": [
        "def test_evaluate():\n",
        "    final_model = GNN(config, global_size, num_tasks)\n",
        "    path = os.path.join(best_model_path, 'checkpoint.pth')\n",
        "    with open(path, 'rb') as f:\n",
        "        checkpoint = cloudpickle.load(f)\n",
        "    final_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    final_model.eval()\n",
        "    test_score = compute_score(final_model, test_dataloader, scaler, len(test_set), num_tasks)\n",
        "\n",
        "    print(\"Test Score: {:.3f}\".format(test_score), \"\\n\")\n",
        "    print(\"Execution time: {:.3f} seconds\".format(time.time() - start_time))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LP0svnJUH4Jq",
        "outputId": "b4bf4fa4-a7ad-4f62-e240-53bf35faba70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 2.657 | Valid Score: 1.510\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 1.510 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 1.665 | Valid Score: 1.429\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 1.429 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 1.514 | Valid Score: 1.399\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 1.399 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 1.450 | Valid Score: 1.385\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 1.385 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 5/100 | Training Loss: 1.401 | Valid Score: 1.366\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 1.366 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 6/100 | Training Loss: 1.361 | Valid Score: 1.348\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 1.348 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 1.316 | Valid Score: 1.339\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 1.339 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 1.280 | Valid Score: 1.328\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 1.328 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 9/100 | Training Loss: 1.256 | Valid Score: 1.328\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 1.328 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 1.233 | Valid Score: 1.310\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 1.310 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 11/100 | Training Loss: 1.212 | Valid Score: 1.314\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 1.310 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 12/100 | Training Loss: 1.193 | Valid Score: 1.302\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 1.302 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 13/100 | Training Loss: 1.185 | Valid Score: 1.295\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 1.295 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 14/100 | Training Loss: 1.164 | Valid Score: 1.292\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 1.292 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 15/100 | Training Loss: 1.151 | Valid Score: 1.289\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 1.289 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 16/100 | Training Loss: 1.141 | Valid Score: 1.284\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 1.284 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 17/100 | Training Loss: 1.127 | Valid Score: 1.284\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 1.284 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 18/100 | Training Loss: 1.118 | Valid Score: 1.278\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 1.278 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 19/100 | Training Loss: 1.107 | Valid Score: 1.275\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 1.275 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 20/100 | Training Loss: 1.095 | Valid Score: 1.272\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 1.272 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 21/100 | Training Loss: 1.083 | Valid Score: 1.269\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 1.269 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 22/100 | Training Loss: 1.083 | Valid Score: 1.271\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 1.269 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 23/100 | Training Loss: 1.068 | Valid Score: 1.266\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 1.266 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 24/100 | Training Loss: 1.061 | Valid Score: 1.266\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 1.266 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 25/100 | Training Loss: 1.064 | Valid Score: 1.264\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 1.264 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 26/100 | Training Loss: 1.046 | Valid Score: 1.272\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 1.264 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 27/100 | Training Loss: 1.036 | Valid Score: 1.264\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 1.264 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 28/100 | Training Loss: 1.029 | Valid Score: 1.263\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 1.263 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 29/100 | Training Loss: 1.017 | Valid Score: 1.258\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 1.258 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 30/100 | Training Loss: 1.020 | Valid Score: 1.265\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 1.258 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 31/100 | Training Loss: 1.005 | Valid Score: 1.253\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 1.253 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 32/100 | Training Loss: 0.999 | Valid Score: 1.255\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 1.253 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 33/100 | Training Loss: 0.998 | Valid Score: 1.252\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 1.252 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 34/100 | Training Loss: 0.985 | Valid Score: 1.253\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 1.252 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 35/100 | Training Loss: 0.984 | Valid Score: 1.262\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 1.252 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 36/100 | Training Loss: 0.985 | Valid Score: 1.249\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 1.249 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 37/100 | Training Loss: 0.977 | Valid Score: 1.262\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 1.249 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 38/100 | Training Loss: 0.981 | Valid Score: 1.275\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 1.249 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 39/100 | Training Loss: 0.968 | Valid Score: 1.248\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 1.248 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 40/100 | Training Loss: 0.967 | Valid Score: 1.249\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 1.248 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 41/100 | Training Loss: 0.966 | Valid Score: 1.267\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 1.248 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 42/100 | Training Loss: 0.966 | Valid Score: 1.249\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 1.248 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 43/100 | Training Loss: 0.963 | Valid Score: 1.242\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 1.242 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 44/100 | Training Loss: 0.939 | Valid Score: 1.241\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 1.241 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 45/100 | Training Loss: 0.938 | Valid Score: 1.241\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 1.241 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 46/100 | Training Loss: 0.933 | Valid Score: 1.240\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 1.240 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 47/100 | Training Loss: 0.930 | Valid Score: 1.244\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 1.240 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 48/100 | Training Loss: 0.925 | Valid Score: 1.238\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 1.238 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 49/100 | Training Loss: 0.923 | Valid Score: 1.238\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 1.238 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 50/100 | Training Loss: 0.914 | Valid Score: 1.239\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 1.238 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 51/100 | Training Loss: 0.925 | Valid Score: 1.249\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 1.238 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 52/100 | Training Loss: 0.912 | Valid Score: 1.236\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 1.236 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 53/100 | Training Loss: 0.901 | Valid Score: 1.239\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 1.236 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 54/100 | Training Loss: 0.900 | Valid Score: 1.238\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 1.236 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 55/100 | Training Loss: 0.902 | Valid Score: 1.235\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 1.235 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 56/100 | Training Loss: 0.894 | Valid Score: 1.235\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 1.235 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 57/100 | Training Loss: 0.894 | Valid Score: 1.251\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 1.235 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 58/100 | Training Loss: 0.895 | Valid Score: 1.233\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 1.233 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 59/100 | Training Loss: 0.888 | Valid Score: 1.236\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 1.233 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 60/100 | Training Loss: 0.890 | Valid Score: 1.235\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 1.233 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 61/100 | Training Loss: 0.882 | Valid Score: 1.230\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 1.230 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 62/100 | Training Loss: 0.882 | Valid Score: 1.233\n",
            " \n",
            "Epoch: 62/100 | Best Valid Score Until Now: 1.230 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 63/100 | Training Loss: 0.871 | Valid Score: 1.230\n",
            " \n",
            "Epoch: 63/100 | Best Valid Score Until Now: 1.230 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 64/100 | Training Loss: 0.869 | Valid Score: 1.233\n",
            " \n",
            "Epoch: 64/100 | Best Valid Score Until Now: 1.230 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 65/100 | Training Loss: 0.873 | Valid Score: 1.230\n",
            " \n",
            "Epoch: 65/100 | Best Valid Score Until Now: 1.230 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 66/100 | Training Loss: 0.866 | Valid Score: 1.234\n",
            " \n",
            "Epoch: 66/100 | Best Valid Score Until Now: 1.230 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 67/100 | Training Loss: 0.877 | Valid Score: 1.238\n",
            " \n",
            "Epoch: 67/100 | Best Valid Score Until Now: 1.230 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 68/100 | Training Loss: 0.859 | Valid Score: 1.228\n",
            " \n",
            "Epoch: 68/100 | Best Valid Score Until Now: 1.228 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 69/100 | Training Loss: 0.868 | Valid Score: 1.230\n",
            " \n",
            "Epoch: 69/100 | Best Valid Score Until Now: 1.228 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 70/100 | Training Loss: 0.869 | Valid Score: 1.228\n",
            " \n",
            "Epoch: 70/100 | Best Valid Score Until Now: 1.228 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 71/100 | Training Loss: 0.849 | Valid Score: 1.229\n",
            " \n",
            "Epoch: 71/100 | Best Valid Score Until Now: 1.228 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 72/100 | Training Loss: 0.851 | Valid Score: 1.224\n",
            " \n",
            "Epoch: 72/100 | Best Valid Score Until Now: 1.224 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 73/100 | Training Loss: 0.842 | Valid Score: 1.225\n",
            " \n",
            "Epoch: 73/100 | Best Valid Score Until Now: 1.224 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 74/100 | Training Loss: 0.841 | Valid Score: 1.225\n",
            " \n",
            "Epoch: 74/100 | Best Valid Score Until Now: 1.224 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 75/100 | Training Loss: 0.843 | Valid Score: 1.226\n",
            " \n",
            "Epoch: 75/100 | Best Valid Score Until Now: 1.224 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 76/100 | Training Loss: 0.837 | Valid Score: 1.227\n",
            " \n",
            "Epoch: 76/100 | Best Valid Score Until Now: 1.224 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 77/100 | Training Loss: 0.834 | Valid Score: 1.224\n",
            " \n",
            "Epoch: 77/100 | Best Valid Score Until Now: 1.224 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 78/100 | Training Loss: 0.829 | Valid Score: 1.230\n",
            " \n",
            "Epoch: 78/100 | Best Valid Score Until Now: 1.224 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 79/100 | Training Loss: 0.825 | Valid Score: 1.222\n",
            " \n",
            "Epoch: 79/100 | Best Valid Score Until Now: 1.222 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 80/100 | Training Loss: 0.830 | Valid Score: 1.224\n",
            " \n",
            "Epoch: 80/100 | Best Valid Score Until Now: 1.222 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 81/100 | Training Loss: 0.825 | Valid Score: 1.231\n",
            " \n",
            "Epoch: 81/100 | Best Valid Score Until Now: 1.222 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 82/100 | Training Loss: 0.821 | Valid Score: 1.222\n",
            " \n",
            "Epoch: 82/100 | Best Valid Score Until Now: 1.222 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 83/100 | Training Loss: 0.820 | Valid Score: 1.223\n",
            " \n",
            "Epoch: 83/100 | Best Valid Score Until Now: 1.222 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 84/100 | Training Loss: 0.811 | Valid Score: 1.225\n",
            " \n",
            "Epoch: 84/100 | Best Valid Score Until Now: 1.222 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 85/100 | Training Loss: 0.813 | Valid Score: 1.222\n",
            " \n",
            "Epoch: 85/100 | Best Valid Score Until Now: 1.222 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 86/100 | Training Loss: 0.812 | Valid Score: 1.224\n",
            " \n",
            "Epoch: 86/100 | Best Valid Score Until Now: 1.222 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 87/100 | Training Loss: 0.816 | Valid Score: 1.218\n",
            " \n",
            "Epoch: 87/100 | Best Valid Score Until Now: 1.218 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 88/100 | Training Loss: 0.807 | Valid Score: 1.226\n",
            " \n",
            "Epoch: 88/100 | Best Valid Score Until Now: 1.218 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 89/100 | Training Loss: 0.806 | Valid Score: 1.221\n",
            " \n",
            "Epoch: 89/100 | Best Valid Score Until Now: 1.218 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 90/100 | Training Loss: 0.800 | Valid Score: 1.220\n",
            " \n",
            "Epoch: 90/100 | Best Valid Score Until Now: 1.218 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 91/100 | Training Loss: 0.800 | Valid Score: 1.220\n",
            " \n",
            "Epoch: 91/100 | Best Valid Score Until Now: 1.218 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 92/100 | Training Loss: 0.799 | Valid Score: 1.219\n",
            " \n",
            "Epoch: 92/100 | Best Valid Score Until Now: 1.218 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 93/100 | Training Loss: 0.795 | Valid Score: 1.221\n",
            " \n",
            "Epoch: 93/100 | Best Valid Score Until Now: 1.218 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 94/100 | Training Loss: 0.793 | Valid Score: 1.234\n",
            " \n",
            "Epoch: 94/100 | Best Valid Score Until Now: 1.218 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 95/100 | Training Loss: 0.795 | Valid Score: 1.224\n",
            " \n",
            "Epoch: 95/100 | Best Valid Score Until Now: 1.218 \n",
            "\n",
            "Patience 9\n",
            "Epoch: 96/100 | Training Loss: 0.801 | Valid Score: 1.219\n",
            " \n",
            "Epoch: 96/100 | Best Valid Score Until Now: 1.218 \n",
            "\n",
            "Patience 10\n",
            "Epoch: 97/100 | Training Loss: 0.791 | Valid Score: 1.227\n",
            " \n",
            "Epoch: 97/100 | Best Valid Score Until Now: 1.218 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 1.218 \n",
            "\n",
            "Test Score: 1.294 \n",
            "\n",
            "Execution time: 116.096 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sl_6jUXB_rSB"
      },
      "source": [
        "#GIN 2Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "BoBmq-Wi_qOx"
      },
      "outputs": [],
      "source": [
        "class GNN(nn.Module):\n",
        "    def __init__(self, config, global_size = 200, num_tasks = 1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = GINConv(nn.Linear(self.node_feature_size, self.hidden_size), aggregator_type='sum')\n",
        "        self.conv2 = GINConv(nn.Linear(self.hidden_size, self.num_tasks), aggregator_type='sum')\n",
        "\n",
        "    # def forward(self, g, in_feat):\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"]= mol_dgl_graph.ndata[\"v\"][:,:self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:,:self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "vnYmtU-j_qce"
      },
      "outputs": [],
      "source": [
        "def compute_score(model, data_loader, scaler, val_size, num_tasks=1):\n",
        "  model.eval()\n",
        "  loss_sum = nn.MSELoss(reduction='sum') # MSE with sum instead of mean, i.e., sum_i[(y_i)^2-(y'_i)^2]\n",
        "  final_loss = 0\n",
        "  state = torch.get_rng_state()\n",
        "  with torch.no_grad():\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(data_loader):\n",
        "       prediction = model(mol_dgl_graph, globals)\n",
        "       prediction = torch.tensor(scaler.inverse_transform(prediction.detach().cpu()))\n",
        "       labels = torch.tensor(scaler.inverse_transform(labels.cpu()))\n",
        "       loss = loss_sum(prediction, labels)\n",
        "       final_loss += loss.item()\n",
        "\n",
        "    final_loss /= val_size\n",
        "    final_loss = math.sqrt(final_loss)\n",
        "\n",
        "  return final_loss / num_tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "6Bxsh0US_qih"
      },
      "outputs": [],
      "source": [
        "def loss_func(output, label, mask, num_tasks):\n",
        "    pos_weight = torch.ones((1, num_tasks))\n",
        "    pos_weight\n",
        "    criterion = nn.MSELoss(reduction='none')\n",
        "    loss = mask*criterion(output,label)\n",
        "    loss = loss.sum() / mask.sum()\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "HmkqMrAi_qoQ"
      },
      "outputs": [],
      "source": [
        "def train_epoch(train_dataloader, model, optimizer):\n",
        "    epoch_train_loss = 0\n",
        "    iterations = 0\n",
        "    model.train() \n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(train_dataloader):\n",
        "        prediction = model(mol_dgl_graph, globals)\n",
        "        loss_train = loss_func(prediction, labels, masks, num_tasks)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_loss += loss_train.detach().item()\n",
        "        iterations += 1\n",
        "    epoch_train_loss /= iterations\n",
        "    return epoch_train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "K1Fi4ahI_qrd"
      },
      "outputs": [],
      "source": [
        "def train_evaluate():\n",
        "\n",
        "    model = GNN(config, global_size, num_tasks)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "    best_val = 100000\n",
        "    patience_count = 1\n",
        "    epoch = 1\n",
        "\n",
        "    while epoch <= num_epochs:\n",
        "        if patience_count <= patience:\n",
        "            model.train()\n",
        "            loss_train = train_epoch(train_dataloader, model, optimizer)\n",
        "            model.eval()\n",
        "            score_val = compute_score(model, val_dataloader,scaler, len(val_set), num_tasks)\n",
        "            if score_val < best_val:\n",
        "                best_val = score_val\n",
        "                print(\"Save checkpoint\")\n",
        "                path = os.path.join(checkpoint_path, 'checkpoint.pth')\n",
        "                dict_checkpoint = {\"score_val\": score_val}\n",
        "                dict_checkpoint.update({\"model_state_dict\": model.state_dict(), \"optimizer_state\": optimizer.state_dict()})\n",
        "                with open(path, \"wb\") as outputfile:\n",
        "                    cloudpickle.dump(dict_checkpoint, outputfile)\n",
        "                patience_count = 1\n",
        "            else:\n",
        "                print(\"Patience\", patience_count)\n",
        "                patience_count += 1\n",
        "\n",
        "            print(\"Epoch: {}/{} | Training Loss: {:.3f} | Valid Score: {:.3f}\".format(\n",
        "            epoch, num_epochs, loss_train, score_val))\n",
        "\n",
        "            print(\" \")\n",
        "            print(\"Epoch: {}/{} | Best Valid Score Until Now: {:.3f}\".format(epoch, num_epochs, best_val), \"\\n\")\n",
        "        epoch += 1\n",
        "\n",
        "    \n",
        "    shutil.rmtree(best_model_path, ignore_errors=True)\n",
        "    shutil.copytree(checkpoint_path, best_model_path)\n",
        "\n",
        "    print(\"Final results:\")\n",
        "    print(\"Average Valid Score: {:.3f}\".format(np.mean(best_val)), \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "1PozV88G_qu0"
      },
      "outputs": [],
      "source": [
        "def test_evaluate():\n",
        "    final_model = GNN(config, global_size, num_tasks)\n",
        "    path = os.path.join(best_model_path, 'checkpoint.pth')\n",
        "    with open(path, 'rb') as f:\n",
        "        checkpoint = cloudpickle.load(f)\n",
        "    final_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    final_model.eval()\n",
        "    test_score = compute_score(final_model, test_dataloader, scaler, len(test_set), num_tasks)\n",
        "\n",
        "    print(\"Test Score: {:.3f}\".format(test_score), \"\\n\")\n",
        "    print(\"Execution time: {:.3f} seconds\".format(time.time() - start_time))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXjRUBZSB30x",
        "outputId": "64291ba5-b196-407e-a9b1-ee2d95f72433"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 5.570 | Valid Score: 2.183\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 2.183 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 2.501 | Valid Score: 1.626\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 1.626 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 1.754 | Valid Score: 1.524\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 1.524 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 1.680 | Valid Score: 1.513\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 1.513 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 5/100 | Training Loss: 1.661 | Valid Score: 1.506\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 1.506 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 6/100 | Training Loss: 1.645 | Valid Score: 1.499\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 1.499 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 1.625 | Valid Score: 1.492\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 1.492 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 1.617 | Valid Score: 1.485\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 1.485 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 9/100 | Training Loss: 1.597 | Valid Score: 1.478\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 1.478 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 1.581 | Valid Score: 1.472\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 1.472 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 11/100 | Training Loss: 1.572 | Valid Score: 1.466\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 1.466 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 12/100 | Training Loss: 1.558 | Valid Score: 1.461\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 1.461 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 13/100 | Training Loss: 1.550 | Valid Score: 1.458\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 1.458 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 14/100 | Training Loss: 1.537 | Valid Score: 1.452\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 1.452 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 15/100 | Training Loss: 1.530 | Valid Score: 1.448\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 1.448 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 16/100 | Training Loss: 1.520 | Valid Score: 1.444\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 1.444 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 17/100 | Training Loss: 1.514 | Valid Score: 1.442\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 1.442 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 18/100 | Training Loss: 1.501 | Valid Score: 1.437\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 1.437 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 19/100 | Training Loss: 1.490 | Valid Score: 1.435\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 1.435 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 20/100 | Training Loss: 1.488 | Valid Score: 1.431\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 1.431 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 21/100 | Training Loss: 1.482 | Valid Score: 1.428\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 1.428 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 22/100 | Training Loss: 1.477 | Valid Score: 1.425\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 1.425 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 23/100 | Training Loss: 1.472 | Valid Score: 1.423\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 1.423 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 24/100 | Training Loss: 1.463 | Valid Score: 1.421\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 1.421 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 25/100 | Training Loss: 1.452 | Valid Score: 1.417\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 1.417 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 26/100 | Training Loss: 1.444 | Valid Score: 1.414\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 1.414 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 27/100 | Training Loss: 1.440 | Valid Score: 1.415\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 1.414 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 28/100 | Training Loss: 1.436 | Valid Score: 1.409\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 1.409 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 29/100 | Training Loss: 1.426 | Valid Score: 1.406\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 1.406 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 30/100 | Training Loss: 1.426 | Valid Score: 1.404\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 1.404 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 31/100 | Training Loss: 1.420 | Valid Score: 1.401\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 1.401 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 32/100 | Training Loss: 1.416 | Valid Score: 1.398\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 1.398 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 33/100 | Training Loss: 1.411 | Valid Score: 1.397\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 1.397 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 34/100 | Training Loss: 1.402 | Valid Score: 1.394\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 1.394 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 35/100 | Training Loss: 1.400 | Valid Score: 1.391\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 1.391 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 36/100 | Training Loss: 1.394 | Valid Score: 1.389\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 1.389 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 37/100 | Training Loss: 1.386 | Valid Score: 1.388\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 1.388 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 38/100 | Training Loss: 1.380 | Valid Score: 1.386\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 1.386 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 39/100 | Training Loss: 1.379 | Valid Score: 1.384\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 1.384 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 40/100 | Training Loss: 1.372 | Valid Score: 1.381\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 1.381 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 41/100 | Training Loss: 1.368 | Valid Score: 1.381\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 1.381 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 42/100 | Training Loss: 1.359 | Valid Score: 1.378\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 1.378 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 43/100 | Training Loss: 1.356 | Valid Score: 1.376\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 1.376 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 44/100 | Training Loss: 1.360 | Valid Score: 1.379\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 1.376 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 45/100 | Training Loss: 1.351 | Valid Score: 1.373\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 1.373 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 46/100 | Training Loss: 1.346 | Valid Score: 1.372\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 1.372 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 47/100 | Training Loss: 1.336 | Valid Score: 1.370\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 1.370 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 48/100 | Training Loss: 1.342 | Valid Score: 1.369\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 1.369 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 49/100 | Training Loss: 1.333 | Valid Score: 1.368\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 1.368 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 50/100 | Training Loss: 1.330 | Valid Score: 1.366\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 1.366 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 51/100 | Training Loss: 1.327 | Valid Score: 1.366\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 1.366 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 52/100 | Training Loss: 1.323 | Valid Score: 1.366\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 1.366 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 53/100 | Training Loss: 1.328 | Valid Score: 1.366\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 1.366 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 54/100 | Training Loss: 1.316 | Valid Score: 1.363\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 1.363 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 55/100 | Training Loss: 1.314 | Valid Score: 1.362\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 1.362 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 56/100 | Training Loss: 1.307 | Valid Score: 1.361\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 1.361 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 57/100 | Training Loss: 1.308 | Valid Score: 1.362\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 1.361 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 58/100 | Training Loss: 1.306 | Valid Score: 1.359\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 1.359 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 59/100 | Training Loss: 1.298 | Valid Score: 1.364\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 1.359 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 60/100 | Training Loss: 1.300 | Valid Score: 1.359\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 1.359 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 61/100 | Training Loss: 1.292 | Valid Score: 1.360\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 1.359 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 62/100 | Training Loss: 1.289 | Valid Score: 1.357\n",
            " \n",
            "Epoch: 62/100 | Best Valid Score Until Now: 1.357 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 63/100 | Training Loss: 1.288 | Valid Score: 1.356\n",
            " \n",
            "Epoch: 63/100 | Best Valid Score Until Now: 1.356 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 64/100 | Training Loss: 1.281 | Valid Score: 1.356\n",
            " \n",
            "Epoch: 64/100 | Best Valid Score Until Now: 1.356 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 65/100 | Training Loss: 1.278 | Valid Score: 1.357\n",
            " \n",
            "Epoch: 65/100 | Best Valid Score Until Now: 1.356 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 66/100 | Training Loss: 1.275 | Valid Score: 1.354\n",
            " \n",
            "Epoch: 66/100 | Best Valid Score Until Now: 1.354 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 67/100 | Training Loss: 1.276 | Valid Score: 1.354\n",
            " \n",
            "Epoch: 67/100 | Best Valid Score Until Now: 1.354 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 68/100 | Training Loss: 1.277 | Valid Score: 1.354\n",
            " \n",
            "Epoch: 68/100 | Best Valid Score Until Now: 1.354 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 69/100 | Training Loss: 1.270 | Valid Score: 1.354\n",
            " \n",
            "Epoch: 69/100 | Best Valid Score Until Now: 1.354 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 70/100 | Training Loss: 1.272 | Valid Score: 1.358\n",
            " \n",
            "Epoch: 70/100 | Best Valid Score Until Now: 1.354 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 71/100 | Training Loss: 1.268 | Valid Score: 1.352\n",
            " \n",
            "Epoch: 71/100 | Best Valid Score Until Now: 1.352 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 72/100 | Training Loss: 1.258 | Valid Score: 1.351\n",
            " \n",
            "Epoch: 72/100 | Best Valid Score Until Now: 1.351 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 73/100 | Training Loss: 1.256 | Valid Score: 1.351\n",
            " \n",
            "Epoch: 73/100 | Best Valid Score Until Now: 1.351 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 74/100 | Training Loss: 1.265 | Valid Score: 1.354\n",
            " \n",
            "Epoch: 74/100 | Best Valid Score Until Now: 1.351 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 75/100 | Training Loss: 1.258 | Valid Score: 1.350\n",
            " \n",
            "Epoch: 75/100 | Best Valid Score Until Now: 1.350 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 76/100 | Training Loss: 1.250 | Valid Score: 1.355\n",
            " \n",
            "Epoch: 76/100 | Best Valid Score Until Now: 1.350 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 77/100 | Training Loss: 1.248 | Valid Score: 1.348\n",
            " \n",
            "Epoch: 77/100 | Best Valid Score Until Now: 1.348 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 78/100 | Training Loss: 1.252 | Valid Score: 1.348\n",
            " \n",
            "Epoch: 78/100 | Best Valid Score Until Now: 1.348 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 79/100 | Training Loss: 1.246 | Valid Score: 1.347\n",
            " \n",
            "Epoch: 79/100 | Best Valid Score Until Now: 1.347 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 80/100 | Training Loss: 1.251 | Valid Score: 1.347\n",
            " \n",
            "Epoch: 80/100 | Best Valid Score Until Now: 1.347 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 81/100 | Training Loss: 1.241 | Valid Score: 1.346\n",
            " \n",
            "Epoch: 81/100 | Best Valid Score Until Now: 1.346 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 82/100 | Training Loss: 1.235 | Valid Score: 1.347\n",
            " \n",
            "Epoch: 82/100 | Best Valid Score Until Now: 1.346 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 83/100 | Training Loss: 1.234 | Valid Score: 1.346\n",
            " \n",
            "Epoch: 83/100 | Best Valid Score Until Now: 1.346 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 84/100 | Training Loss: 1.234 | Valid Score: 1.345\n",
            " \n",
            "Epoch: 84/100 | Best Valid Score Until Now: 1.345 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 85/100 | Training Loss: 1.228 | Valid Score: 1.350\n",
            " \n",
            "Epoch: 85/100 | Best Valid Score Until Now: 1.345 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 86/100 | Training Loss: 1.231 | Valid Score: 1.345\n",
            " \n",
            "Epoch: 86/100 | Best Valid Score Until Now: 1.345 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 87/100 | Training Loss: 1.231 | Valid Score: 1.345\n",
            " \n",
            "Epoch: 87/100 | Best Valid Score Until Now: 1.345 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 88/100 | Training Loss: 1.231 | Valid Score: 1.342\n",
            " \n",
            "Epoch: 88/100 | Best Valid Score Until Now: 1.342 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 89/100 | Training Loss: 1.225 | Valid Score: 1.345\n",
            " \n",
            "Epoch: 89/100 | Best Valid Score Until Now: 1.342 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 90/100 | Training Loss: 1.219 | Valid Score: 1.343\n",
            " \n",
            "Epoch: 90/100 | Best Valid Score Until Now: 1.342 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 91/100 | Training Loss: 1.219 | Valid Score: 1.341\n",
            " \n",
            "Epoch: 91/100 | Best Valid Score Until Now: 1.341 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 92/100 | Training Loss: 1.218 | Valid Score: 1.342\n",
            " \n",
            "Epoch: 92/100 | Best Valid Score Until Now: 1.341 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 93/100 | Training Loss: 1.213 | Valid Score: 1.341\n",
            " \n",
            "Epoch: 93/100 | Best Valid Score Until Now: 1.341 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 94/100 | Training Loss: 1.212 | Valid Score: 1.340\n",
            " \n",
            "Epoch: 94/100 | Best Valid Score Until Now: 1.340 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 95/100 | Training Loss: 1.207 | Valid Score: 1.340\n",
            " \n",
            "Epoch: 95/100 | Best Valid Score Until Now: 1.340 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 96/100 | Training Loss: 1.209 | Valid Score: 1.339\n",
            " \n",
            "Epoch: 96/100 | Best Valid Score Until Now: 1.339 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 97/100 | Training Loss: 1.207 | Valid Score: 1.340\n",
            " \n",
            "Epoch: 97/100 | Best Valid Score Until Now: 1.339 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 98/100 | Training Loss: 1.203 | Valid Score: 1.338\n",
            " \n",
            "Epoch: 98/100 | Best Valid Score Until Now: 1.338 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 99/100 | Training Loss: 1.196 | Valid Score: 1.341\n",
            " \n",
            "Epoch: 99/100 | Best Valid Score Until Now: 1.338 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 100/100 | Training Loss: 1.203 | Valid Score: 1.337\n",
            " \n",
            "Epoch: 100/100 | Best Valid Score Until Now: 1.337 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 1.337 \n",
            "\n",
            "Test Score: 1.389 \n",
            "\n",
            "Execution time: 104.493 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiXCuddQ_VA5"
      },
      "source": [
        "#GIN 3Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "D895VZtW_PB_"
      },
      "outputs": [],
      "source": [
        "class GNN(nn.Module):\n",
        "    def __init__(self, config, global_size=200, num_tasks=1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = GINConv(nn.Linear(self.node_feature_size, self.hidden_size), aggregator_type='sum')\n",
        "        self.conv2 = GINConv(nn.Linear(self.hidden_size, self.hidden_size), aggregator_type='sum')\n",
        "        self.conv3 = GINConv(nn.Linear(self.hidden_size, self.num_tasks), aggregator_type='sum')\n",
        "\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"] = mol_dgl_graph.ndata[\"v\"][:, :self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:, :self.edge_feature_size]\n",
        "\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv3(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "lv_Xw6IH_PN5"
      },
      "outputs": [],
      "source": [
        "def compute_score(model, data_loader, scaler, val_size, num_tasks=1):\n",
        "  model.eval()\n",
        "  loss_sum = nn.MSELoss(reduction='sum') # MSE with sum instead of mean, i.e., sum_i[(y_i)^2-(y'_i)^2]\n",
        "  final_loss = 0\n",
        "  state = torch.get_rng_state()\n",
        "  with torch.no_grad():\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(data_loader):\n",
        "       prediction = model(mol_dgl_graph, globals)\n",
        "       prediction = torch.tensor(scaler.inverse_transform(prediction.detach().cpu()))\n",
        "       labels = torch.tensor(scaler.inverse_transform(labels.cpu()))\n",
        "       loss = loss_sum(prediction, labels)\n",
        "       final_loss += loss.item()\n",
        "\n",
        "    final_loss /= val_size\n",
        "    final_loss = math.sqrt(final_loss)\n",
        "\n",
        "  return final_loss / num_tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "R5yITYY0_PVy"
      },
      "outputs": [],
      "source": [
        "def loss_func(output, label, mask, num_tasks):\n",
        "    pos_weight = torch.ones((1, num_tasks))\n",
        "    pos_weight\n",
        "    criterion = nn.MSELoss(reduction='none')\n",
        "    loss = mask*criterion(output,label)\n",
        "    loss = loss.sum() / mask.sum()\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "cbKt7YQ9_PdK"
      },
      "outputs": [],
      "source": [
        "def train_epoch(train_dataloader, model, optimizer):\n",
        "    epoch_train_loss = 0\n",
        "    iterations = 0\n",
        "    model.train() \n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(train_dataloader):\n",
        "        prediction = model(mol_dgl_graph, globals)\n",
        "        loss_train = loss_func(prediction, labels, masks, num_tasks)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_loss += loss_train.detach().item()\n",
        "        iterations += 1\n",
        "    epoch_train_loss /= iterations\n",
        "    return epoch_train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "DYUahHhQ_PjR"
      },
      "outputs": [],
      "source": [
        "def train_evaluate():\n",
        "\n",
        "    model = GNN(config, global_size, num_tasks)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "    best_val = 100000\n",
        "    patience_count = 1\n",
        "    epoch = 1\n",
        "\n",
        "    while epoch <= num_epochs:\n",
        "        if patience_count <= patience:\n",
        "            model.train()\n",
        "            loss_train = train_epoch(train_dataloader, model, optimizer)\n",
        "            model.eval()\n",
        "            score_val = compute_score(model, val_dataloader,scaler, len(val_set), num_tasks)\n",
        "            if score_val < best_val:\n",
        "                best_val = score_val\n",
        "                print(\"Save checkpoint\")\n",
        "                path = os.path.join(checkpoint_path, 'checkpoint.pth')\n",
        "                dict_checkpoint = {\"score_val\": score_val}\n",
        "                dict_checkpoint.update({\"model_state_dict\": model.state_dict(), \"optimizer_state\": optimizer.state_dict()})\n",
        "                with open(path, \"wb\") as outputfile:\n",
        "                    cloudpickle.dump(dict_checkpoint, outputfile)\n",
        "                patience_count = 1\n",
        "            else:\n",
        "                print(\"Patience\", patience_count)\n",
        "                patience_count += 1\n",
        "\n",
        "            print(\"Epoch: {}/{} | Training Loss: {:.3f} | Valid Score: {:.3f}\".format(\n",
        "            epoch, num_epochs, loss_train, score_val))\n",
        "\n",
        "            print(\" \")\n",
        "            print(\"Epoch: {}/{} | Best Valid Score Until Now: {:.3f}\".format(epoch, num_epochs, best_val), \"\\n\")\n",
        "        epoch += 1\n",
        "\n",
        "    \n",
        "    shutil.rmtree(best_model_path, ignore_errors=True)\n",
        "    shutil.copytree(checkpoint_path, best_model_path)\n",
        "\n",
        "    print(\"Final results:\")\n",
        "    print(\"Average Valid Score: {:.3f}\".format(np.mean(best_val)), \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "GXEphZ0u_PpB"
      },
      "outputs": [],
      "source": [
        "def test_evaluate():\n",
        "    final_model = GNN(config, global_size, num_tasks)\n",
        "    path = os.path.join(best_model_path, 'checkpoint.pth')\n",
        "    with open(path, 'rb') as f:\n",
        "        checkpoint = cloudpickle.load(f)\n",
        "    final_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    final_model.eval()\n",
        "    test_score = compute_score(final_model, test_dataloader, scaler, len(test_set), num_tasks)\n",
        "\n",
        "    print(\"Test Score: {:.3f}\".format(test_score), \"\\n\")\n",
        "    print(\"Execution time: {:.3f} seconds\".format(time.time() - start_time))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOtE5j3G_Pvu",
        "outputId": "9dfaa5dd-828a-4b47-e86b-245daa965964"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 4.092 | Valid Score: 1.552\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 1.552 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 1.660 | Valid Score: 1.526\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 1.526 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 1.611 | Valid Score: 1.509\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 1.509 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 1.594 | Valid Score: 1.498\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 1.498 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 5/100 | Training Loss: 1.558 | Valid Score: 1.489\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 1.489 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 6/100 | Training Loss: 1.535 | Valid Score: 1.478\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 1.478 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 1.529 | Valid Score: 1.466\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 1.466 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 1.503 | Valid Score: 1.458\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 1.458 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 9/100 | Training Loss: 1.483 | Valid Score: 1.444\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 1.444 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 1.468 | Valid Score: 1.438\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 1.438 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 11/100 | Training Loss: 1.448 | Valid Score: 1.428\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 1.428 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 12/100 | Training Loss: 1.432 | Valid Score: 1.430\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 1.428 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 13/100 | Training Loss: 1.414 | Valid Score: 1.418\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 1.418 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 14/100 | Training Loss: 1.392 | Valid Score: 1.412\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 1.412 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 15/100 | Training Loss: 1.375 | Valid Score: 1.405\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 1.405 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 16/100 | Training Loss: 1.362 | Valid Score: 1.406\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 1.405 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 17/100 | Training Loss: 1.344 | Valid Score: 1.400\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 1.400 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 18/100 | Training Loss: 1.325 | Valid Score: 1.395\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 1.395 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 19/100 | Training Loss: 1.315 | Valid Score: 1.396\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 1.395 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 20/100 | Training Loss: 1.303 | Valid Score: 1.383\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 1.383 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 21/100 | Training Loss: 1.292 | Valid Score: 1.381\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 1.381 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 22/100 | Training Loss: 1.266 | Valid Score: 1.383\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 1.381 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 23/100 | Training Loss: 1.268 | Valid Score: 1.374\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 1.374 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 24/100 | Training Loss: 1.253 | Valid Score: 1.369\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 1.369 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 25/100 | Training Loss: 1.231 | Valid Score: 1.364\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 1.364 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 26/100 | Training Loss: 1.227 | Valid Score: 1.370\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 1.364 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 27/100 | Training Loss: 1.214 | Valid Score: 1.368\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 1.364 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 28/100 | Training Loss: 1.211 | Valid Score: 1.358\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 1.358 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 29/100 | Training Loss: 1.195 | Valid Score: 1.351\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 1.351 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 30/100 | Training Loss: 1.194 | Valid Score: 1.352\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 1.351 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 31/100 | Training Loss: 1.172 | Valid Score: 1.347\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 1.347 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 32/100 | Training Loss: 1.181 | Valid Score: 1.344\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 1.344 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 33/100 | Training Loss: 1.156 | Valid Score: 1.349\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 1.344 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 34/100 | Training Loss: 1.168 | Valid Score: 1.344\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 1.344 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 35/100 | Training Loss: 1.148 | Valid Score: 1.337\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 1.337 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 36/100 | Training Loss: 1.143 | Valid Score: 1.336\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 1.336 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 37/100 | Training Loss: 1.139 | Valid Score: 1.334\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 1.334 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 38/100 | Training Loss: 1.138 | Valid Score: 1.332\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 1.332 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 39/100 | Training Loss: 1.124 | Valid Score: 1.334\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 1.332 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 40/100 | Training Loss: 1.113 | Valid Score: 1.329\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 1.329 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 41/100 | Training Loss: 1.115 | Valid Score: 1.345\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 1.329 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 42/100 | Training Loss: 1.105 | Valid Score: 1.325\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 1.325 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 43/100 | Training Loss: 1.113 | Valid Score: 1.368\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 1.325 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 44/100 | Training Loss: 1.103 | Valid Score: 1.338\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 1.325 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 45/100 | Training Loss: 1.090 | Valid Score: 1.318\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 1.318 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 46/100 | Training Loss: 1.079 | Valid Score: 1.320\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 1.318 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 47/100 | Training Loss: 1.086 | Valid Score: 1.332\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 1.318 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 48/100 | Training Loss: 1.082 | Valid Score: 1.334\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 1.318 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 49/100 | Training Loss: 1.068 | Valid Score: 1.313\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 1.313 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 50/100 | Training Loss: 1.068 | Valid Score: 1.313\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 1.313 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 51/100 | Training Loss: 1.068 | Valid Score: 1.317\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 1.313 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 52/100 | Training Loss: 1.063 | Valid Score: 1.309\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 1.309 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 53/100 | Training Loss: 1.061 | Valid Score: 1.309\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 1.309 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 54/100 | Training Loss: 1.062 | Valid Score: 1.317\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 1.309 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 55/100 | Training Loss: 1.054 | Valid Score: 1.305\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 1.305 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 56/100 | Training Loss: 1.053 | Valid Score: 1.304\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 1.304 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 57/100 | Training Loss: 1.065 | Valid Score: 1.318\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 1.304 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 58/100 | Training Loss: 1.040 | Valid Score: 1.303\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 1.303 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 59/100 | Training Loss: 1.035 | Valid Score: 1.299\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 1.299 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 60/100 | Training Loss: 1.037 | Valid Score: 1.300\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 1.299 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 61/100 | Training Loss: 1.025 | Valid Score: 1.307\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 1.299 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 62/100 | Training Loss: 1.024 | Valid Score: 1.308\n",
            " \n",
            "Epoch: 62/100 | Best Valid Score Until Now: 1.299 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 63/100 | Training Loss: 1.026 | Valid Score: 1.328\n",
            " \n",
            "Epoch: 63/100 | Best Valid Score Until Now: 1.299 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 64/100 | Training Loss: 1.058 | Valid Score: 1.302\n",
            " \n",
            "Epoch: 64/100 | Best Valid Score Until Now: 1.299 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 65/100 | Training Loss: 1.013 | Valid Score: 1.295\n",
            " \n",
            "Epoch: 65/100 | Best Valid Score Until Now: 1.295 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 66/100 | Training Loss: 1.003 | Valid Score: 1.295\n",
            " \n",
            "Epoch: 66/100 | Best Valid Score Until Now: 1.295 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 67/100 | Training Loss: 1.005 | Valid Score: 1.294\n",
            " \n",
            "Epoch: 67/100 | Best Valid Score Until Now: 1.294 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 68/100 | Training Loss: 1.007 | Valid Score: 1.291\n",
            " \n",
            "Epoch: 68/100 | Best Valid Score Until Now: 1.291 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 69/100 | Training Loss: 0.998 | Valid Score: 1.316\n",
            " \n",
            "Epoch: 69/100 | Best Valid Score Until Now: 1.291 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 70/100 | Training Loss: 1.015 | Valid Score: 1.290\n",
            " \n",
            "Epoch: 70/100 | Best Valid Score Until Now: 1.290 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 71/100 | Training Loss: 0.997 | Valid Score: 1.289\n",
            " \n",
            "Epoch: 71/100 | Best Valid Score Until Now: 1.289 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 72/100 | Training Loss: 1.002 | Valid Score: 1.284\n",
            " \n",
            "Epoch: 72/100 | Best Valid Score Until Now: 1.284 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 73/100 | Training Loss: 0.996 | Valid Score: 1.303\n",
            " \n",
            "Epoch: 73/100 | Best Valid Score Until Now: 1.284 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 74/100 | Training Loss: 0.991 | Valid Score: 1.289\n",
            " \n",
            "Epoch: 74/100 | Best Valid Score Until Now: 1.284 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 75/100 | Training Loss: 0.977 | Valid Score: 1.297\n",
            " \n",
            "Epoch: 75/100 | Best Valid Score Until Now: 1.284 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 76/100 | Training Loss: 0.988 | Valid Score: 1.286\n",
            " \n",
            "Epoch: 76/100 | Best Valid Score Until Now: 1.284 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 77/100 | Training Loss: 0.977 | Valid Score: 1.284\n",
            " \n",
            "Epoch: 77/100 | Best Valid Score Until Now: 1.284 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 78/100 | Training Loss: 0.967 | Valid Score: 1.279\n",
            " \n",
            "Epoch: 78/100 | Best Valid Score Until Now: 1.279 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 79/100 | Training Loss: 0.972 | Valid Score: 1.319\n",
            " \n",
            "Epoch: 79/100 | Best Valid Score Until Now: 1.279 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 80/100 | Training Loss: 0.973 | Valid Score: 1.307\n",
            " \n",
            "Epoch: 80/100 | Best Valid Score Until Now: 1.279 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 81/100 | Training Loss: 0.967 | Valid Score: 1.280\n",
            " \n",
            "Epoch: 81/100 | Best Valid Score Until Now: 1.279 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 82/100 | Training Loss: 0.963 | Valid Score: 1.280\n",
            " \n",
            "Epoch: 82/100 | Best Valid Score Until Now: 1.279 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 83/100 | Training Loss: 0.954 | Valid Score: 1.286\n",
            " \n",
            "Epoch: 83/100 | Best Valid Score Until Now: 1.279 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 84/100 | Training Loss: 0.952 | Valid Score: 1.289\n",
            " \n",
            "Epoch: 84/100 | Best Valid Score Until Now: 1.279 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 85/100 | Training Loss: 0.951 | Valid Score: 1.311\n",
            " \n",
            "Epoch: 85/100 | Best Valid Score Until Now: 1.279 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 86/100 | Training Loss: 0.951 | Valid Score: 1.280\n",
            " \n",
            "Epoch: 86/100 | Best Valid Score Until Now: 1.279 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 87/100 | Training Loss: 0.942 | Valid Score: 1.279\n",
            " \n",
            "Epoch: 87/100 | Best Valid Score Until Now: 1.279 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 88/100 | Training Loss: 0.943 | Valid Score: 1.278\n",
            " \n",
            "Epoch: 88/100 | Best Valid Score Until Now: 1.278 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 89/100 | Training Loss: 0.945 | Valid Score: 1.277\n",
            " \n",
            "Epoch: 89/100 | Best Valid Score Until Now: 1.277 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 90/100 | Training Loss: 0.935 | Valid Score: 1.272\n",
            " \n",
            "Epoch: 90/100 | Best Valid Score Until Now: 1.272 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 91/100 | Training Loss: 0.953 | Valid Score: 1.277\n",
            " \n",
            "Epoch: 91/100 | Best Valid Score Until Now: 1.272 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 92/100 | Training Loss: 0.927 | Valid Score: 1.289\n",
            " \n",
            "Epoch: 92/100 | Best Valid Score Until Now: 1.272 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 93/100 | Training Loss: 0.938 | Valid Score: 1.280\n",
            " \n",
            "Epoch: 93/100 | Best Valid Score Until Now: 1.272 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 94/100 | Training Loss: 0.928 | Valid Score: 1.270\n",
            " \n",
            "Epoch: 94/100 | Best Valid Score Until Now: 1.270 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 95/100 | Training Loss: 0.923 | Valid Score: 1.277\n",
            " \n",
            "Epoch: 95/100 | Best Valid Score Until Now: 1.270 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 96/100 | Training Loss: 0.928 | Valid Score: 1.292\n",
            " \n",
            "Epoch: 96/100 | Best Valid Score Until Now: 1.270 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 97/100 | Training Loss: 0.925 | Valid Score: 1.269\n",
            " \n",
            "Epoch: 97/100 | Best Valid Score Until Now: 1.269 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 98/100 | Training Loss: 0.917 | Valid Score: 1.284\n",
            " \n",
            "Epoch: 98/100 | Best Valid Score Until Now: 1.269 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 99/100 | Training Loss: 0.914 | Valid Score: 1.269\n",
            " \n",
            "Epoch: 99/100 | Best Valid Score Until Now: 1.269 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 100/100 | Training Loss: 0.913 | Valid Score: 1.267\n",
            " \n",
            "Epoch: 100/100 | Best Valid Score Until Now: 1.267 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 1.267 \n",
            "\n",
            "Test Score: 1.301 \n",
            "\n",
            "Execution time: 115.714 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DGH7FAYCZQI"
      },
      "source": [
        "#GAT 2Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "umBAGosvCq9T"
      },
      "outputs": [],
      "source": [
        "class GNN(nn.Module):\n",
        "    def __init__(self, config, global_size = 200, num_tasks = 1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.num_heads = self.config.get('num_heads', 1)\n",
        "        self.dropout = self.config.get('dropout', 0.0)\n",
        "\n",
        "        self.conv1 = GATConv(\n",
        "            self.node_feature_size,\n",
        "            self.hidden_size,\n",
        "            num_heads=self.num_heads,\n",
        "            feat_drop=self.dropout,\n",
        "            attn_drop=self.dropout,allow_zero_in_degree=True)\n",
        "\n",
        "        self.fc = nn.Linear(\n",
        "            self.hidden_size * self.num_heads,\n",
        "            self.hidden_size)\n",
        "        self.conv2 = GATConv(\n",
        "            self.hidden_size,\n",
        "            self.num_tasks,\n",
        "            num_heads=1,\n",
        "            feat_drop=self.dropout,\n",
        "            attn_drop=self.dropout,allow_zero_in_degree=True\n",
        "       )\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"] = mol_dgl_graph.ndata[\"v\"][:, :self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:, :self.edge_feature_size]\n",
        "\n",
        "        # First GAT layer\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"]).flatten(1)\n",
        "        h = F.relu(h)\n",
        "        h = self.fc(h)\n",
        "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
        "\n",
        "        # Second GAT layer\n",
        "        h = self.conv2(mol_dgl_graph, h).squeeze(1)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "h0-KWZeACrGh"
      },
      "outputs": [],
      "source": [
        "def compute_score(model, data_loader, scaler, val_size, num_tasks=1):\n",
        "  model.eval()\n",
        "  loss_sum = nn.MSELoss(reduction='sum') # MSE with sum instead of mean, i.e., sum_i[(y_i)^2-(y'_i)^2]\n",
        "  final_loss = 0\n",
        "  state = torch.get_rng_state()\n",
        "  with torch.no_grad():\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(data_loader):\n",
        "       prediction = model(mol_dgl_graph, globals)\n",
        "       prediction = torch.tensor(scaler.inverse_transform(prediction.detach().cpu()))\n",
        "       labels = torch.tensor(scaler.inverse_transform(labels.cpu()))\n",
        "       loss = loss_sum(prediction, labels)\n",
        "       final_loss += loss.item()\n",
        "\n",
        "    final_loss /= val_size\n",
        "    final_loss = math.sqrt(final_loss)\n",
        "\n",
        "  return final_loss / num_tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "YsiUisOZCrMK"
      },
      "outputs": [],
      "source": [
        "def loss_func(output, label, mask, num_tasks):\n",
        "    pos_weight = torch.ones((1, num_tasks))\n",
        "    pos_weight\n",
        "    criterion = nn.MSELoss(reduction='none')\n",
        "    loss = mask*criterion(output,label)\n",
        "    loss = loss.sum() / mask.sum()\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "g98mtDZeCrQI"
      },
      "outputs": [],
      "source": [
        "def train_epoch(train_dataloader, model, optimizer):\n",
        "    epoch_train_loss = 0\n",
        "    iterations = 0\n",
        "    model.train() \n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(train_dataloader):\n",
        "        prediction = model(mol_dgl_graph, globals)\n",
        "        loss_train = loss_func(prediction, labels, masks, num_tasks)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_loss += loss_train.detach().item()\n",
        "        iterations += 1\n",
        "    epoch_train_loss /= iterations\n",
        "    return epoch_train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "5RGoUWXzCrTP"
      },
      "outputs": [],
      "source": [
        "def train_evaluate():\n",
        "\n",
        "    model = GNN(config, global_size, num_tasks)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "    best_val = 100000\n",
        "    patience_count = 1\n",
        "    epoch = 1\n",
        "\n",
        "    while epoch <= num_epochs:\n",
        "        if patience_count <= patience:\n",
        "            model.train()\n",
        "            loss_train = train_epoch(train_dataloader, model, optimizer)\n",
        "            model.eval()\n",
        "            score_val = compute_score(model, val_dataloader,scaler, len(val_set), num_tasks)\n",
        "            if score_val < best_val:\n",
        "                best_val = score_val\n",
        "                print(\"Save checkpoint\")\n",
        "                path = os.path.join(checkpoint_path, 'checkpoint.pth')\n",
        "                dict_checkpoint = {\"score_val\": score_val}\n",
        "                dict_checkpoint.update({\"model_state_dict\": model.state_dict(), \"optimizer_state\": optimizer.state_dict()})\n",
        "                with open(path, \"wb\") as outputfile:\n",
        "                    cloudpickle.dump(dict_checkpoint, outputfile)\n",
        "                patience_count = 1\n",
        "            else:\n",
        "                print(\"Patience\", patience_count)\n",
        "                patience_count += 1\n",
        "\n",
        "            print(\"Epoch: {}/{} | Training Loss: {:.3f} | Valid Score: {:.3f}\".format(\n",
        "            epoch, num_epochs, loss_train, score_val))\n",
        "\n",
        "            print(\" \")\n",
        "            print(\"Epoch: {}/{} | Best Valid Score Until Now: {:.3f}\".format(epoch, num_epochs, best_val), \"\\n\")\n",
        "        epoch += 1\n",
        "\n",
        "    \n",
        "    shutil.rmtree(best_model_path, ignore_errors=True)\n",
        "    shutil.copytree(checkpoint_path, best_model_path)\n",
        "\n",
        "    print(\"Final results:\")\n",
        "    print(\"Average Valid Score: {:.3f}\".format(np.mean(best_val)), \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "fNbDvF7VDZdh"
      },
      "outputs": [],
      "source": [
        "def test_evaluate():\n",
        "    final_model = GNN(config, global_size, num_tasks)\n",
        "    path = os.path.join(best_model_path, 'checkpoint.pth')\n",
        "    with open(path, 'rb') as f:\n",
        "        checkpoint = cloudpickle.load(f)\n",
        "    final_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    final_model.eval()\n",
        "    test_score = compute_score(final_model, test_dataloader, scaler, len(test_set), num_tasks)\n",
        "\n",
        "    print(\"Test Score: {:.3f}\".format(test_score), \"\\n\")\n",
        "    print(\"Execution time: {:.3f} seconds\".format(time.time() - start_time))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOK-YadsDZk_",
        "outputId": "9c1591d3-8474-429a-d71b-34e564847a4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 4.017 | Valid Score: 1.698\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 1.698 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 1.838 | Valid Score: 1.511\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 1.511 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 1.718 | Valid Score: 1.495\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 1.495 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 1.686 | Valid Score: 1.481\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 1.481 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 5/100 | Training Loss: 1.653 | Valid Score: 1.468\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 1.468 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 6/100 | Training Loss: 1.619 | Valid Score: 1.456\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 1.456 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 1.590 | Valid Score: 1.442\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 1.442 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 1.560 | Valid Score: 1.430\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 1.430 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 9/100 | Training Loss: 1.533 | Valid Score: 1.420\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 1.420 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 1.515 | Valid Score: 1.412\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 1.412 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 11/100 | Training Loss: 1.487 | Valid Score: 1.403\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 1.403 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 12/100 | Training Loss: 1.475 | Valid Score: 1.396\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 1.396 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 13/100 | Training Loss: 1.452 | Valid Score: 1.389\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 1.389 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 14/100 | Training Loss: 1.441 | Valid Score: 1.383\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 1.383 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 15/100 | Training Loss: 1.422 | Valid Score: 1.376\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 1.376 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 16/100 | Training Loss: 1.404 | Valid Score: 1.370\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 1.370 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 17/100 | Training Loss: 1.397 | Valid Score: 1.365\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 1.365 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 18/100 | Training Loss: 1.378 | Valid Score: 1.361\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 1.361 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 19/100 | Training Loss: 1.365 | Valid Score: 1.355\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 1.355 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 20/100 | Training Loss: 1.353 | Valid Score: 1.364\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 1.355 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 21/100 | Training Loss: 1.340 | Valid Score: 1.345\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 1.345 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 22/100 | Training Loss: 1.322 | Valid Score: 1.343\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 1.343 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 23/100 | Training Loss: 1.316 | Valid Score: 1.337\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 1.337 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 24/100 | Training Loss: 1.302 | Valid Score: 1.333\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 1.333 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 25/100 | Training Loss: 1.298 | Valid Score: 1.328\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 1.328 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 26/100 | Training Loss: 1.287 | Valid Score: 1.325\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 1.325 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 27/100 | Training Loss: 1.272 | Valid Score: 1.321\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 1.321 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 28/100 | Training Loss: 1.262 | Valid Score: 1.317\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 1.317 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 29/100 | Training Loss: 1.250 | Valid Score: 1.317\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 1.317 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 30/100 | Training Loss: 1.244 | Valid Score: 1.312\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 1.312 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 31/100 | Training Loss: 1.237 | Valid Score: 1.313\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 1.312 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 32/100 | Training Loss: 1.230 | Valid Score: 1.309\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 1.309 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 33/100 | Training Loss: 1.220 | Valid Score: 1.307\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 1.307 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 34/100 | Training Loss: 1.211 | Valid Score: 1.307\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 1.307 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 35/100 | Training Loss: 1.200 | Valid Score: 1.302\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 1.302 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 36/100 | Training Loss: 1.183 | Valid Score: 1.300\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 1.300 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 37/100 | Training Loss: 1.181 | Valid Score: 1.299\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 1.299 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 38/100 | Training Loss: 1.167 | Valid Score: 1.296\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 1.296 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 39/100 | Training Loss: 1.159 | Valid Score: 1.293\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 1.293 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 40/100 | Training Loss: 1.158 | Valid Score: 1.292\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 1.292 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 41/100 | Training Loss: 1.142 | Valid Score: 1.290\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 1.290 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 42/100 | Training Loss: 1.130 | Valid Score: 1.293\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 1.290 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 43/100 | Training Loss: 1.127 | Valid Score: 1.286\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 1.286 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 44/100 | Training Loss: 1.123 | Valid Score: 1.285\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 1.285 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 45/100 | Training Loss: 1.115 | Valid Score: 1.285\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 1.285 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 46/100 | Training Loss: 1.114 | Valid Score: 1.283\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 1.283 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 47/100 | Training Loss: 1.114 | Valid Score: 1.282\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 1.282 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 48/100 | Training Loss: 1.108 | Valid Score: 1.282\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 1.282 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 49/100 | Training Loss: 1.099 | Valid Score: 1.279\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 1.279 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 50/100 | Training Loss: 1.100 | Valid Score: 1.279\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 1.279 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 51/100 | Training Loss: 1.094 | Valid Score: 1.278\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 1.278 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 52/100 | Training Loss: 1.088 | Valid Score: 1.282\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 1.278 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 53/100 | Training Loss: 1.086 | Valid Score: 1.277\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 1.277 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 54/100 | Training Loss: 1.083 | Valid Score: 1.277\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 1.277 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 55/100 | Training Loss: 1.084 | Valid Score: 1.278\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 1.277 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 56/100 | Training Loss: 1.082 | Valid Score: 1.276\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 1.276 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 57/100 | Training Loss: 1.077 | Valid Score: 1.274\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 1.274 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 58/100 | Training Loss: 1.073 | Valid Score: 1.277\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 1.274 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 59/100 | Training Loss: 1.069 | Valid Score: 1.273\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 1.273 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 60/100 | Training Loss: 1.071 | Valid Score: 1.272\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 1.272 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 61/100 | Training Loss: 1.071 | Valid Score: 1.279\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 1.272 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 62/100 | Training Loss: 1.063 | Valid Score: 1.273\n",
            " \n",
            "Epoch: 62/100 | Best Valid Score Until Now: 1.272 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 63/100 | Training Loss: 1.061 | Valid Score: 1.269\n",
            " \n",
            "Epoch: 63/100 | Best Valid Score Until Now: 1.269 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 64/100 | Training Loss: 1.061 | Valid Score: 1.268\n",
            " \n",
            "Epoch: 64/100 | Best Valid Score Until Now: 1.268 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 65/100 | Training Loss: 1.057 | Valid Score: 1.268\n",
            " \n",
            "Epoch: 65/100 | Best Valid Score Until Now: 1.268 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 66/100 | Training Loss: 1.049 | Valid Score: 1.272\n",
            " \n",
            "Epoch: 66/100 | Best Valid Score Until Now: 1.268 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 67/100 | Training Loss: 1.050 | Valid Score: 1.273\n",
            " \n",
            "Epoch: 67/100 | Best Valid Score Until Now: 1.268 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 68/100 | Training Loss: 1.052 | Valid Score: 1.265\n",
            " \n",
            "Epoch: 68/100 | Best Valid Score Until Now: 1.265 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 69/100 | Training Loss: 1.043 | Valid Score: 1.269\n",
            " \n",
            "Epoch: 69/100 | Best Valid Score Until Now: 1.265 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 70/100 | Training Loss: 1.045 | Valid Score: 1.271\n",
            " \n",
            "Epoch: 70/100 | Best Valid Score Until Now: 1.265 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 71/100 | Training Loss: 1.043 | Valid Score: 1.264\n",
            " \n",
            "Epoch: 71/100 | Best Valid Score Until Now: 1.264 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 72/100 | Training Loss: 1.048 | Valid Score: 1.266\n",
            " \n",
            "Epoch: 72/100 | Best Valid Score Until Now: 1.264 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 73/100 | Training Loss: 1.037 | Valid Score: 1.265\n",
            " \n",
            "Epoch: 73/100 | Best Valid Score Until Now: 1.264 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 74/100 | Training Loss: 1.038 | Valid Score: 1.265\n",
            " \n",
            "Epoch: 74/100 | Best Valid Score Until Now: 1.264 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 75/100 | Training Loss: 1.038 | Valid Score: 1.261\n",
            " \n",
            "Epoch: 75/100 | Best Valid Score Until Now: 1.261 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 76/100 | Training Loss: 1.032 | Valid Score: 1.267\n",
            " \n",
            "Epoch: 76/100 | Best Valid Score Until Now: 1.261 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 77/100 | Training Loss: 1.037 | Valid Score: 1.270\n",
            " \n",
            "Epoch: 77/100 | Best Valid Score Until Now: 1.261 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 78/100 | Training Loss: 1.027 | Valid Score: 1.260\n",
            " \n",
            "Epoch: 78/100 | Best Valid Score Until Now: 1.260 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 79/100 | Training Loss: 1.030 | Valid Score: 1.267\n",
            " \n",
            "Epoch: 79/100 | Best Valid Score Until Now: 1.260 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 80/100 | Training Loss: 1.030 | Valid Score: 1.259\n",
            " \n",
            "Epoch: 80/100 | Best Valid Score Until Now: 1.259 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 81/100 | Training Loss: 1.021 | Valid Score: 1.259\n",
            " \n",
            "Epoch: 81/100 | Best Valid Score Until Now: 1.259 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 82/100 | Training Loss: 1.023 | Valid Score: 1.260\n",
            " \n",
            "Epoch: 82/100 | Best Valid Score Until Now: 1.259 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 83/100 | Training Loss: 1.020 | Valid Score: 1.260\n",
            " \n",
            "Epoch: 83/100 | Best Valid Score Until Now: 1.259 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 84/100 | Training Loss: 1.021 | Valid Score: 1.259\n",
            " \n",
            "Epoch: 84/100 | Best Valid Score Until Now: 1.259 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 85/100 | Training Loss: 1.018 | Valid Score: 1.258\n",
            " \n",
            "Epoch: 85/100 | Best Valid Score Until Now: 1.258 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 86/100 | Training Loss: 1.015 | Valid Score: 1.262\n",
            " \n",
            "Epoch: 86/100 | Best Valid Score Until Now: 1.258 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 87/100 | Training Loss: 1.020 | Valid Score: 1.257\n",
            " \n",
            "Epoch: 87/100 | Best Valid Score Until Now: 1.257 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 88/100 | Training Loss: 1.021 | Valid Score: 1.257\n",
            " \n",
            "Epoch: 88/100 | Best Valid Score Until Now: 1.257 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 89/100 | Training Loss: 1.012 | Valid Score: 1.256\n",
            " \n",
            "Epoch: 89/100 | Best Valid Score Until Now: 1.256 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 90/100 | Training Loss: 1.013 | Valid Score: 1.256\n",
            " \n",
            "Epoch: 90/100 | Best Valid Score Until Now: 1.256 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 91/100 | Training Loss: 1.011 | Valid Score: 1.256\n",
            " \n",
            "Epoch: 91/100 | Best Valid Score Until Now: 1.256 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 92/100 | Training Loss: 1.011 | Valid Score: 1.255\n",
            " \n",
            "Epoch: 92/100 | Best Valid Score Until Now: 1.255 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 93/100 | Training Loss: 1.006 | Valid Score: 1.254\n",
            " \n",
            "Epoch: 93/100 | Best Valid Score Until Now: 1.254 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 94/100 | Training Loss: 1.009 | Valid Score: 1.256\n",
            " \n",
            "Epoch: 94/100 | Best Valid Score Until Now: 1.254 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 95/100 | Training Loss: 1.011 | Valid Score: 1.255\n",
            " \n",
            "Epoch: 95/100 | Best Valid Score Until Now: 1.254 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 96/100 | Training Loss: 1.002 | Valid Score: 1.255\n",
            " \n",
            "Epoch: 96/100 | Best Valid Score Until Now: 1.254 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 97/100 | Training Loss: 1.008 | Valid Score: 1.251\n",
            " \n",
            "Epoch: 97/100 | Best Valid Score Until Now: 1.251 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 98/100 | Training Loss: 1.008 | Valid Score: 1.252\n",
            " \n",
            "Epoch: 98/100 | Best Valid Score Until Now: 1.251 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 99/100 | Training Loss: 1.000 | Valid Score: 1.253\n",
            " \n",
            "Epoch: 99/100 | Best Valid Score Until Now: 1.251 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 100/100 | Training Loss: 0.995 | Valid Score: 1.253\n",
            " \n",
            "Epoch: 100/100 | Best Valid Score Until Now: 1.251 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 1.251 \n",
            "\n",
            "Test Score: 1.328 \n",
            "\n",
            "Execution time: 128.650 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGPvaz--CsoI"
      },
      "source": [
        "#GAT 3Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "yDEFXafYCv0I"
      },
      "outputs": [],
      "source": [
        "class GNN(nn.Module):\n",
        "    def __init__(self, config, global_size=200, num_tasks=1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "\n",
        "        \n",
        "        self.num_heads = self.config.get('num_heads', 1)\n",
        "\n",
        "        \n",
        "        self.dropout = self.config.get('dropout', 0.0)\n",
        "\n",
        "        # GAT layer1\n",
        "        self.conv1 = GATConv(self.node_feature_size,self.hidden_size,num_heads=self.num_heads,feat_drop=self.dropout,attn_drop=self.dropout,allow_zero_in_degree=True)\n",
        "\n",
        "        # Linear layer\n",
        "        self.fc = nn.Linear(self.hidden_size * self.num_heads,self.hidden_size)\n",
        "\n",
        "        # GAT layer2\n",
        "        self.conv2 = GATConv(self.hidden_size,self.hidden_size,num_heads=1,feat_drop=self.dropout,attn_drop=self.dropout,allow_zero_in_degree=True)\n",
        "\n",
        "        # GAT layer3\n",
        "        self.conv3 = GATConv(self.hidden_size,self.num_tasks,num_heads=1,feat_drop=self.dropout,attn_drop=self.dropout,allow_zero_in_degree=True)\n",
        "\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"] = mol_dgl_graph.ndata[\"v\"][:, :self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:, :self.edge_feature_size]\n",
        "\n",
        "        # First GAT layer\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"]).flatten(1)\n",
        "        h = F.relu(h)\n",
        "        h = self.fc(h)\n",
        "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
        "\n",
        "        # Second GAT layer\n",
        "        h = self.conv2(mol_dgl_graph, h).squeeze(1)\n",
        "        h = F.relu(h)\n",
        "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
        "\n",
        "        # Third GAT layer\n",
        "        if self.num_tasks == 1:\n",
        "            h = self.conv3(mol_dgl_graph, h).squeeze(1)\n",
        "        else:\n",
        "            hs = []\n",
        "            for i in range(self.num_tasks):\n",
        "                hi = self.conv3(mol_dgl_graph, h).squeeze(1)\n",
        "                hs.append(hi)\n",
        "            h = torch.stack(hs, dim=1)\n",
        "\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "\n",
        "        if self.num_tasks == 1:\n",
        "            return dgl.mean_nodes(mol_dgl_graph, \"h\")\n",
        "        else:\n",
        "            return dgl.mean_nodes(mol_dgl_graph, \"h\"), h\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "VH8J0U6ECv3Z"
      },
      "outputs": [],
      "source": [
        "def compute_score(model, data_loader, scaler, val_size, num_tasks=1):\n",
        "  model.eval()\n",
        "  loss_sum = nn.MSELoss(reduction='sum') # MSE with sum instead of mean, i.e., sum_i[(y_i)^2-(y'_i)^2]\n",
        "  final_loss = 0\n",
        "  state = torch.get_rng_state()\n",
        "  with torch.no_grad():\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(data_loader):\n",
        "       prediction = model(mol_dgl_graph, globals)\n",
        "       prediction = torch.tensor(scaler.inverse_transform(prediction.detach().cpu()))\n",
        "       labels = torch.tensor(scaler.inverse_transform(labels.cpu()))\n",
        "       loss = loss_sum(prediction, labels)\n",
        "       final_loss += loss.item()\n",
        "\n",
        "    final_loss /= val_size\n",
        "    final_loss = math.sqrt(final_loss)\n",
        "\n",
        "  return final_loss / num_tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "77MjnJLsCv6Y"
      },
      "outputs": [],
      "source": [
        "def loss_func(output, label, mask, num_tasks):\n",
        "    pos_weight = torch.ones((1, num_tasks))\n",
        "    pos_weight\n",
        "    criterion = nn.MSELoss(reduction='none')\n",
        "    loss = mask*criterion(output,label)\n",
        "    loss = loss.sum() / mask.sum()\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "eeSTcyPtCv9K"
      },
      "outputs": [],
      "source": [
        "def train_epoch(train_dataloader, model, optimizer):\n",
        "    epoch_train_loss = 0\n",
        "    iterations = 0\n",
        "    model.train() \n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(train_dataloader):\n",
        "        prediction = model(mol_dgl_graph, globals)\n",
        "        loss_train = loss_func(prediction, labels, masks, num_tasks)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_loss += loss_train.detach().item()\n",
        "        iterations += 1\n",
        "    epoch_train_loss /= iterations\n",
        "    return epoch_train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "AKSC2-qJCv_y"
      },
      "outputs": [],
      "source": [
        "def train_evaluate():\n",
        "\n",
        "    model = GNN(config, global_size, num_tasks)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "    best_val = 100000\n",
        "    patience_count = 1\n",
        "    epoch = 1\n",
        "\n",
        "    while epoch <= num_epochs:\n",
        "        if patience_count <= patience:\n",
        "            model.train()\n",
        "            loss_train = train_epoch(train_dataloader, model, optimizer)\n",
        "            model.eval()\n",
        "            score_val = compute_score(model, val_dataloader,scaler, len(val_set), num_tasks)\n",
        "            if score_val < best_val:\n",
        "                best_val = score_val\n",
        "                print(\"Save checkpoint\")\n",
        "                path = os.path.join(checkpoint_path, 'checkpoint.pth')\n",
        "                dict_checkpoint = {\"score_val\": score_val}\n",
        "                dict_checkpoint.update({\"model_state_dict\": model.state_dict(), \"optimizer_state\": optimizer.state_dict()})\n",
        "                with open(path, \"wb\") as outputfile:\n",
        "                    cloudpickle.dump(dict_checkpoint, outputfile)\n",
        "                patience_count = 1\n",
        "            else:\n",
        "                print(\"Patience\", patience_count)\n",
        "                patience_count += 1\n",
        "\n",
        "            print(\"Epoch: {}/{} | Training Loss: {:.3f} | Valid Score: {:.3f}\".format(\n",
        "            epoch, num_epochs, loss_train, score_val))\n",
        "\n",
        "            print(\" \")\n",
        "            print(\"Epoch: {}/{} | Best Valid Score Until Now: {:.3f}\".format(epoch, num_epochs, best_val), \"\\n\")\n",
        "        epoch += 1\n",
        "\n",
        "    \n",
        "    shutil.rmtree(best_model_path, ignore_errors=True)\n",
        "    shutil.copytree(checkpoint_path, best_model_path)\n",
        "\n",
        "    print(\"Final results:\")\n",
        "    print(\"Average Valid Score: {:.3f}\".format(np.mean(best_val)), \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "YDBamc59CwEN"
      },
      "outputs": [],
      "source": [
        "def test_evaluate():\n",
        "    final_model = GNN(config, global_size, num_tasks)\n",
        "    path = os.path.join(best_model_path, 'checkpoint.pth')\n",
        "    with open(path, 'rb') as f:\n",
        "        checkpoint = cloudpickle.load(f)\n",
        "    final_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    final_model.eval()\n",
        "    test_score = compute_score(final_model, test_dataloader, scaler, len(test_set), num_tasks)\n",
        "\n",
        "    print(\"Test Score: {:.3f}\".format(test_score), \"\\n\")\n",
        "    print(\"Execution time: {:.3f} seconds\".format(time.time() - start_time))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8nsIS9cD81Q",
        "outputId": "2a27f97a-ce64-44d4-bed3-b367c12e0483"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 2.427 | Valid Score: 1.567\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 1.567 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 1.802 | Valid Score: 1.489\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 1.489 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 1.632 | Valid Score: 1.443\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 1.443 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 1.549 | Valid Score: 1.421\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 1.421 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 5/100 | Training Loss: 1.505 | Valid Score: 1.413\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 1.413 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 6/100 | Training Loss: 1.485 | Valid Score: 1.401\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 1.401 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 1.448 | Valid Score: 1.398\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 1.398 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 1.436 | Valid Score: 1.391\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 1.391 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 9/100 | Training Loss: 1.433 | Valid Score: 1.386\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 1.386 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 1.408 | Valid Score: 1.383\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 1.383 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 11/100 | Training Loss: 1.398 | Valid Score: 1.377\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 1.377 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 12/100 | Training Loss: 1.389 | Valid Score: 1.373\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 1.373 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 13/100 | Training Loss: 1.363 | Valid Score: 1.376\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 1.373 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 14/100 | Training Loss: 1.351 | Valid Score: 1.368\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 1.368 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 15/100 | Training Loss: 1.331 | Valid Score: 1.360\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 1.360 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 16/100 | Training Loss: 1.322 | Valid Score: 1.356\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 1.356 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 17/100 | Training Loss: 1.310 | Valid Score: 1.357\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 1.356 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 18/100 | Training Loss: 1.303 | Valid Score: 1.347\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 1.347 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 19/100 | Training Loss: 1.289 | Valid Score: 1.344\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 1.344 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 20/100 | Training Loss: 1.282 | Valid Score: 1.346\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 1.344 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 21/100 | Training Loss: 1.273 | Valid Score: 1.335\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 1.335 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 22/100 | Training Loss: 1.253 | Valid Score: 1.336\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 1.335 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 23/100 | Training Loss: 1.251 | Valid Score: 1.348\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 1.335 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 24/100 | Training Loss: 1.252 | Valid Score: 1.322\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 1.322 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 25/100 | Training Loss: 1.235 | Valid Score: 1.319\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 1.319 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 26/100 | Training Loss: 1.218 | Valid Score: 1.315\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 1.315 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 27/100 | Training Loss: 1.209 | Valid Score: 1.313\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 1.313 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 28/100 | Training Loss: 1.210 | Valid Score: 1.309\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 1.309 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 29/100 | Training Loss: 1.204 | Valid Score: 1.300\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 1.300 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 30/100 | Training Loss: 1.188 | Valid Score: 1.296\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 1.296 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 31/100 | Training Loss: 1.185 | Valid Score: 1.304\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 1.296 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 32/100 | Training Loss: 1.173 | Valid Score: 1.288\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 1.288 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 33/100 | Training Loss: 1.164 | Valid Score: 1.288\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 1.288 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 34/100 | Training Loss: 1.154 | Valid Score: 1.284\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 1.284 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 35/100 | Training Loss: 1.169 | Valid Score: 1.285\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 1.284 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 36/100 | Training Loss: 1.151 | Valid Score: 1.273\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 1.273 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 37/100 | Training Loss: 1.141 | Valid Score: 1.284\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 1.273 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 38/100 | Training Loss: 1.130 | Valid Score: 1.274\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 1.273 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 39/100 | Training Loss: 1.126 | Valid Score: 1.265\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 1.265 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 40/100 | Training Loss: 1.118 | Valid Score: 1.262\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 1.262 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 41/100 | Training Loss: 1.125 | Valid Score: 1.274\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 1.262 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 42/100 | Training Loss: 1.110 | Valid Score: 1.253\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 1.253 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 43/100 | Training Loss: 1.118 | Valid Score: 1.251\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 1.251 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 44/100 | Training Loss: 1.098 | Valid Score: 1.253\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 1.251 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 45/100 | Training Loss: 1.106 | Valid Score: 1.248\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 1.248 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 46/100 | Training Loss: 1.094 | Valid Score: 1.244\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 1.244 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 47/100 | Training Loss: 1.089 | Valid Score: 1.240\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 1.240 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 48/100 | Training Loss: 1.086 | Valid Score: 1.240\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 1.240 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 49/100 | Training Loss: 1.075 | Valid Score: 1.242\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 1.240 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 50/100 | Training Loss: 1.085 | Valid Score: 1.241\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 1.240 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 51/100 | Training Loss: 1.073 | Valid Score: 1.234\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 1.234 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 52/100 | Training Loss: 1.063 | Valid Score: 1.232\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 1.232 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 53/100 | Training Loss: 1.069 | Valid Score: 1.237\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 1.232 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 54/100 | Training Loss: 1.064 | Valid Score: 1.237\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 1.232 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 55/100 | Training Loss: 1.063 | Valid Score: 1.228\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 1.228 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 56/100 | Training Loss: 1.049 | Valid Score: 1.224\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 1.224 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 57/100 | Training Loss: 1.052 | Valid Score: 1.224\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 1.224 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 58/100 | Training Loss: 1.048 | Valid Score: 1.224\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 1.224 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 59/100 | Training Loss: 1.043 | Valid Score: 1.227\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 1.224 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 60/100 | Training Loss: 1.041 | Valid Score: 1.226\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 1.224 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 61/100 | Training Loss: 1.042 | Valid Score: 1.220\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 1.220 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 62/100 | Training Loss: 1.044 | Valid Score: 1.218\n",
            " \n",
            "Epoch: 62/100 | Best Valid Score Until Now: 1.218 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 63/100 | Training Loss: 1.029 | Valid Score: 1.218\n",
            " \n",
            "Epoch: 63/100 | Best Valid Score Until Now: 1.218 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 64/100 | Training Loss: 1.028 | Valid Score: 1.244\n",
            " \n",
            "Epoch: 64/100 | Best Valid Score Until Now: 1.218 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 65/100 | Training Loss: 1.027 | Valid Score: 1.232\n",
            " \n",
            "Epoch: 65/100 | Best Valid Score Until Now: 1.218 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 66/100 | Training Loss: 1.030 | Valid Score: 1.214\n",
            " \n",
            "Epoch: 66/100 | Best Valid Score Until Now: 1.214 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 67/100 | Training Loss: 1.024 | Valid Score: 1.215\n",
            " \n",
            "Epoch: 67/100 | Best Valid Score Until Now: 1.214 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 68/100 | Training Loss: 1.019 | Valid Score: 1.214\n",
            " \n",
            "Epoch: 68/100 | Best Valid Score Until Now: 1.214 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 69/100 | Training Loss: 1.016 | Valid Score: 1.216\n",
            " \n",
            "Epoch: 69/100 | Best Valid Score Until Now: 1.214 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 70/100 | Training Loss: 1.007 | Valid Score: 1.212\n",
            " \n",
            "Epoch: 70/100 | Best Valid Score Until Now: 1.212 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 71/100 | Training Loss: 1.003 | Valid Score: 1.209\n",
            " \n",
            "Epoch: 71/100 | Best Valid Score Until Now: 1.209 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 72/100 | Training Loss: 1.001 | Valid Score: 1.215\n",
            " \n",
            "Epoch: 72/100 | Best Valid Score Until Now: 1.209 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 73/100 | Training Loss: 1.004 | Valid Score: 1.235\n",
            " \n",
            "Epoch: 73/100 | Best Valid Score Until Now: 1.209 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 74/100 | Training Loss: 1.011 | Valid Score: 1.212\n",
            " \n",
            "Epoch: 74/100 | Best Valid Score Until Now: 1.209 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 75/100 | Training Loss: 0.994 | Valid Score: 1.212\n",
            " \n",
            "Epoch: 75/100 | Best Valid Score Until Now: 1.209 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 76/100 | Training Loss: 0.987 | Valid Score: 1.208\n",
            " \n",
            "Epoch: 76/100 | Best Valid Score Until Now: 1.208 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 77/100 | Training Loss: 0.988 | Valid Score: 1.207\n",
            " \n",
            "Epoch: 77/100 | Best Valid Score Until Now: 1.207 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 78/100 | Training Loss: 0.993 | Valid Score: 1.221\n",
            " \n",
            "Epoch: 78/100 | Best Valid Score Until Now: 1.207 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 79/100 | Training Loss: 0.984 | Valid Score: 1.209\n",
            " \n",
            "Epoch: 79/100 | Best Valid Score Until Now: 1.207 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 80/100 | Training Loss: 0.981 | Valid Score: 1.206\n",
            " \n",
            "Epoch: 80/100 | Best Valid Score Until Now: 1.206 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 81/100 | Training Loss: 0.981 | Valid Score: 1.205\n",
            " \n",
            "Epoch: 81/100 | Best Valid Score Until Now: 1.205 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 82/100 | Training Loss: 0.982 | Valid Score: 1.205\n",
            " \n",
            "Epoch: 82/100 | Best Valid Score Until Now: 1.205 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 83/100 | Training Loss: 0.972 | Valid Score: 1.209\n",
            " \n",
            "Epoch: 83/100 | Best Valid Score Until Now: 1.205 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 84/100 | Training Loss: 0.975 | Valid Score: 1.211\n",
            " \n",
            "Epoch: 84/100 | Best Valid Score Until Now: 1.205 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 85/100 | Training Loss: 0.978 | Valid Score: 1.208\n",
            " \n",
            "Epoch: 85/100 | Best Valid Score Until Now: 1.205 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 86/100 | Training Loss: 0.977 | Valid Score: 1.202\n",
            " \n",
            "Epoch: 86/100 | Best Valid Score Until Now: 1.202 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 87/100 | Training Loss: 0.969 | Valid Score: 1.204\n",
            " \n",
            "Epoch: 87/100 | Best Valid Score Until Now: 1.202 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 88/100 | Training Loss: 0.961 | Valid Score: 1.206\n",
            " \n",
            "Epoch: 88/100 | Best Valid Score Until Now: 1.202 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 89/100 | Training Loss: 0.964 | Valid Score: 1.201\n",
            " \n",
            "Epoch: 89/100 | Best Valid Score Until Now: 1.201 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 90/100 | Training Loss: 0.966 | Valid Score: 1.204\n",
            " \n",
            "Epoch: 90/100 | Best Valid Score Until Now: 1.201 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 91/100 | Training Loss: 0.964 | Valid Score: 1.200\n",
            " \n",
            "Epoch: 91/100 | Best Valid Score Until Now: 1.200 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 92/100 | Training Loss: 0.955 | Valid Score: 1.202\n",
            " \n",
            "Epoch: 92/100 | Best Valid Score Until Now: 1.200 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 93/100 | Training Loss: 0.956 | Valid Score: 1.203\n",
            " \n",
            "Epoch: 93/100 | Best Valid Score Until Now: 1.200 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 94/100 | Training Loss: 0.954 | Valid Score: 1.207\n",
            " \n",
            "Epoch: 94/100 | Best Valid Score Until Now: 1.200 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 95/100 | Training Loss: 0.949 | Valid Score: 1.203\n",
            " \n",
            "Epoch: 95/100 | Best Valid Score Until Now: 1.200 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 96/100 | Training Loss: 0.951 | Valid Score: 1.217\n",
            " \n",
            "Epoch: 96/100 | Best Valid Score Until Now: 1.200 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 97/100 | Training Loss: 0.948 | Valid Score: 1.207\n",
            " \n",
            "Epoch: 97/100 | Best Valid Score Until Now: 1.200 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 98/100 | Training Loss: 0.948 | Valid Score: 1.201\n",
            " \n",
            "Epoch: 98/100 | Best Valid Score Until Now: 1.200 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 99/100 | Training Loss: 0.943 | Valid Score: 1.206\n",
            " \n",
            "Epoch: 99/100 | Best Valid Score Until Now: 1.200 \n",
            "\n",
            "Patience 9\n",
            "Epoch: 100/100 | Training Loss: 0.949 | Valid Score: 1.222\n",
            " \n",
            "Epoch: 100/100 | Best Valid Score Until Now: 1.200 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 1.200 \n",
            "\n",
            "Test Score: 1.310 \n",
            "\n",
            "Execution time: 148.537 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
